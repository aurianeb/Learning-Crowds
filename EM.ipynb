{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithme EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srotc_000\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:1350: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigma(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class model:\n",
    "    \"\"\"Classe qui encapsule l'apprentissage\"\"\"\n",
    "    \n",
    "    def __init__(self, D, R):\n",
    "        \"\"\"Constructeur\"\"\"\n",
    "        \n",
    "        self.D = D #Nombre de variables explicatives\n",
    "        self.R = R #Nombre d'annotateurs\n",
    "     \n",
    "    \n",
    "    def chargeData(self, path, recentrage = True):\n",
    "        \"\"\"Fonction qui charge les données avec path le chemin du fichier CSV. \n",
    "        Par défault, on impose un recentrage des donnée\"\"\"\n",
    "        \n",
    "        data = pd.read_csv(path, delimiter = \";\")\n",
    "        self.trueLabel = np.array(data.ix[:,self.D])\n",
    "        self.y = np.array(data.ix[:,self.D+1:]) #labels des annotateurs\n",
    "        x = np.array(data.ix[:,0:self.D]) #variables explicatives\n",
    "        if (recentrage):\n",
    "            self.x = (x -np.mean(x,axis=0))/(np.std(x, axis=0))\n",
    "        else:\n",
    "            self.x = x\n",
    "        self.N = self.y.shape[0] #Nombre de lignes\n",
    "     \n",
    "    \n",
    "    def initMu(self):\n",
    "        \"\"\"Initialisation de mu\"\"\"\n",
    "        \n",
    "        self.mu = []\n",
    "        for i in range(0,self.N):\n",
    "            self.mu.append(np.sum(self.y[i])/self.R)\n",
    "    \n",
    "    \n",
    "    def ai(self):\n",
    "        \"\"\"Update du vecteur a (1xN)\"\"\"\n",
    "        \n",
    "        a = []\n",
    "        for i in range(0,self.N):\n",
    "            proda = 1\n",
    "            for j in range(0,self.R):\n",
    "                proda = proda*self.alpha[j]**(self.y[i][j])*(1-self.alpha[j])**(1-self.y[i][j])\n",
    "            a.append(proda)\n",
    "        self.a = a\n",
    "    \n",
    "    \n",
    "    def bi(self):\n",
    "        \"\"\"Update du vecteur b (1xN)\"\"\"\n",
    "        \n",
    "        b = []\n",
    "        for i in range(0,self.N):\n",
    "            prodb = 1\n",
    "            for j in range(0,self.R):\n",
    "                prodb = prodb*self.beta[j]**(1-self.y[i][j])*(1-self.beta[j])**(self.y[i][j])\n",
    "            b.append(prodb)\n",
    "        self.b = b\n",
    "       \n",
    "    \n",
    "    def pi(self):\n",
    "        \"\"\"Update du vecteur p (1xN)\"\"\"\n",
    "        \n",
    "        p = []\n",
    "        for i in range(0,self.N):\n",
    "            p.append(sigma(self.x[i].dot(self.w.T)))\n",
    "        self.p = p\n",
    "       \n",
    "    \n",
    "    def mui(self):\n",
    "        \"\"\"Update du vecteur mu (1xN). C'est l'étape E.\"\"\"\n",
    "        self.ai()\n",
    "        self.bi()\n",
    "        self.pi()\n",
    "        mu = []\n",
    "        for i in range(0,self.N):\n",
    "            mu.append(self.a[i]*self.p[i]/(self.a[i]*self.p[i]+self.b[i]*(1-self.p[i])))\n",
    "        self.mu = mu        \n",
    "      \n",
    "    \n",
    "    def logLikelihood(self):\n",
    "        \"\"\"Calcul de la log-vraissemblance.\"\"\"\n",
    "        \n",
    "        self.ai()\n",
    "        self.bi()\n",
    "        self.pi()\n",
    "    \n",
    "        #On calcule directement la log-vraissemblance.\n",
    "        vraissemblance = 0\n",
    "        for i in range(0,self.N):\n",
    "            vraissemblance = vraissemblance + np.log((self.a[i]*self.p[i])+self.b[i]*(1-self.p[i]))\n",
    "        return vraissemblance\n",
    "    \n",
    "    \n",
    "    def alphaUpdate(self):\n",
    "        \"\"\"Update du vecteur alpha sensitivity (1xR)\"\"\"\n",
    "        \n",
    "        alpha = []\n",
    "        for j in range(0,self.R):\n",
    "            tmp1 = 0\n",
    "            tmp2 = 0\n",
    "            for i in range(0,self.N):\n",
    "                tmp1 += self.mu[i]*self.y[i][j]\n",
    "                tmp2 += self.mu[i]\n",
    "            alpha.append(tmp1/tmp2)\n",
    "        self.alpha = alpha\n",
    "\n",
    "        \n",
    "    def betaUpdate(self):\n",
    "        \"\"\"Update du vecteur beta specificity (1xR)\"\"\"\n",
    "        \n",
    "        beta = []\n",
    "        for j in range(0,self.R):\n",
    "            tmp1 = 0\n",
    "            tmp2 = 0\n",
    "            for i in range(0,self.N):\n",
    "                tmp1 += (1-self.mu[i])*(1-self.y[i][j])\n",
    "                tmp2 += 1-self.mu[i]\n",
    "            beta.append(tmp1/tmp2)\n",
    "        self.beta = beta\n",
    "\n",
    "        \n",
    "    def wUpdate(self):\n",
    "        \"\"\"Update du vecteur poids w (1xR)\"\"\"\n",
    "        \n",
    "        g = 0\n",
    "        for i in range(0,self.N):\n",
    "            g += (self.mu[i] - sigma(self.x[i].dot(self.w.T)))*self.x[i]\n",
    "\n",
    "        H = np.zeros((self.D,self.D))\n",
    "        for i in range(0,self.N):\n",
    "            H -= sigma(self.x[i].dot(self.w.T))*(1-sigma(self.x[i].dot(self.w.T)))*((self.x[i].reshape(self.D,1))*(self.x[i].reshape(1,self.D)))\n",
    "        self.w = self.w - self.eta*np.linalg.inv(H).dot(g)\n",
    "    \n",
    "    \n",
    "    def score(self, seuil = 1/2):\n",
    "        \"\"\"Quel est le score d'apprentissage de notre modèle ?\"\"\"\n",
    "        return np.mean(np.equal(self.trueLabel, np.array(self.mu)>seuil))\n",
    "    \n",
    "    \n",
    "    def scoreMoy(self, seuil = 1/2):\n",
    "        \"\"\"Quel serait le score si on fesait naïvement la moyenne des avis des annotateurs ?\"\"\"\n",
    "        return np.mean(np.equal(self.trueLabel, np.mean(self.y, axis = 1)>seuil))\n",
    "\n",
    "    \n",
    "    def train(self, maxIter = 1000, eta = 0.01, epsilon = 0.01, graphe=True):\n",
    "        \"\"\"Fonction qui lance l'entrainement du modèle.\n",
    "        La variable graphe sert à plotter la log-likelihood au fil des itérations.\n",
    "        La log-likelihood devrait être croissante.\"\"\"\n",
    "        \n",
    "        self.maxIter = maxIter\n",
    "        self.eta = eta\n",
    "        \n",
    "        self.initMu()\n",
    "        self.alphaUpdate()\n",
    "        self.betaUpdate()\n",
    "        self.w = np.random.rand(1,self.D)\n",
    "\n",
    "        compteur = 0\n",
    "        self.histLogLikelihood = []\n",
    "        #while (np.linalg.norm(diff_w) > 0.001) : # Limite de convergence à decider\n",
    "        while (compteur < maxIter):\n",
    "            self.mui()\n",
    "            self.alphaUpdate()\n",
    "            self.betaUpdate()\n",
    "            wOld = self.w\n",
    "            self.wUpdate()\n",
    "            wNew = self.w\n",
    "            \n",
    "            self.histLogLikelihood.append(self.logLikelihood())\n",
    "            diffW = wOld - wNew\n",
    "            if (np.linalg.norm(diffW) < epsilon):\n",
    "                print(\"SEUIL DE CONVERGENCE SUR W ATTEINT\")\n",
    "                print (\"ITERATION : \", compteur)\n",
    "                print(\"Vraissemblance : \", self.logLikelihood())\n",
    "                print(\"Norme de diff_w : \", np.linalg.norm(diffW))\n",
    "                print(\"Alpha : \", self.alpha)\n",
    "                print(\"Beta : \", self.beta)\n",
    "                break\n",
    "            \n",
    "            if (compteur % 100 == 0):\n",
    "                print (\"ITERATION : \", compteur)\n",
    "                print(\"Vraissemblance : \", self.logLikelihood())\n",
    "                print(\"Norme de diff_w : \", np.linalg.norm(diffW))\n",
    "                print(\"Alpha : \", self.alpha)\n",
    "                print(\"Beta : \", self.beta)\n",
    "            compteur = compteur + 1\n",
    "        \n",
    "        if graphe:\n",
    "            plt.plot(self.histLogLikelihood)\n",
    "            plt.title('Log-vraissemblance au fil des itérations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION :  0\n",
      "Vraissemblance :  [-1540.71374229]\n",
      "Norme de diff_w :  8.02989844189\n",
      "Alpha :  [array([ 0.91577825]), array([ 0.72352169]), array([ 0.55209697]), array([ 0.47587819]), array([ 0.13467161])]\n",
      "Beta :  [array([ 0.12978667]), array([ 0.31105812]), array([ 0.54870244]), array([ 0.5978354]), array([ 0.89001799])]\n",
      "ITERATION :  100\n",
      "Vraissemblance :  [-1521.24121293]\n",
      "Norme de diff_w :  1.24107500424\n",
      "Alpha :  [array([ 0.93742535]), array([ 0.65491426]), array([ 0.45333863]), array([ 0.3331041]), array([ 0.11486843])]\n",
      "Beta :  [array([ 0.14569254]), array([ 0.25579971]), array([ 0.46777796]), array([ 0.48279359]), array([ 0.87366965])]\n",
      "ITERATION :  200\n",
      "Vraissemblance :  [-1511.94861155]\n",
      "Norme de diff_w :  1837.1203839\n",
      "Alpha :  [array([ 0.93181469]), array([ 0.65149608]), array([ 0.45454802]), array([ 0.31819935]), array([ 0.12121825])]\n",
      "Beta :  [array([ 0.1442559]), array([ 0.24916822]), array([ 0.46557953]), array([ 0.46231999]), array([ 0.87869384])]\n",
      "ITERATION :  300\n",
      "Vraissemblance :  [-1512.14026779]\n",
      "Norme de diff_w :  100.645402346\n",
      "Alpha :  [array([ 0.93148653]), array([ 0.64981121]), array([ 0.45189224]), array([ 0.31973839]), array([ 0.12175796])]\n",
      "Beta :  [array([ 0.14366036]), array([ 0.24813305]), array([ 0.46363117]), array([ 0.46454625]), array([ 0.87915715])]\n",
      "ITERATION :  400\n",
      "Vraissemblance :  [-1512.57083254]\n",
      "Norme de diff_w :  1.73575131906\n",
      "Alpha :  [array([ 0.93131412]), array([ 0.64893886]), array([ 0.45432776]), array([ 0.32053409]), array([ 0.12210821])]\n",
      "Beta :  [array([ 0.14335171]), array([ 0.2476075]), array([ 0.46589211]), array([ 0.46568907]), array([ 0.87945423])]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMDOzkjhhmJlZSZwwzMysJP8f0WN46FjU/50AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29b823bc6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "breast = model(10, 5)\n",
    "breast.chargeData('Datasets/breastCancer.csv')\n",
    "breast.train(maxIter = 500, eta = 1, graphe = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LE SCORE D'ENTRAINEMENT EST DE :  0.508285432773\n",
      "LE SCORE NAIF DE MOYENNE DES ANNOTATEURS EST DE :  0.479789103691\n"
     ]
    }
   ],
   "source": [
    "print(\"LE SCORE D'ENTRAINEMENT EST DE : \", breast.score())\n",
    "print(\"LE SCORE NAIF DE MOYENNE DES ANNOTATEURS EST DE : \", breast.scoreMoy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOUT CE QUI SUIT EST DU BROUILLON POUR LE DEVELOPPEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = 10  #descripteurs\n",
    "N =  wine.shape[0] #produits à tester\n",
    "R = 5 #experts\n",
    "\n",
    "y = np.array(wine.ix[:,d+1:]) #labels des annotateurs\n",
    "x = np.array(wine.ix[:,0:d]) #variables explicatives\n",
    "w0 = np.random.rand(1,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = (x -np.mean(x,axis=0))/(np.std(x, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def init_mu(y):\n",
    "\tmu = []\n",
    "\tfor i in range(0,N):\n",
    "\t\tmu.append(np.sum(y[i])/R)\n",
    "\treturn mu\n",
    "\n",
    "\n",
    "\n",
    "mu0 = init_mu(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#E-step\n",
    "\n",
    "def ai(alpha,y):\n",
    "    a = []\n",
    "    for i in range(0,N):\n",
    "        proda = 1\n",
    "        for j in range(0,R):\n",
    "            proda = proda*alpha[j]**(y[i][j])*(1-alpha[j])**(1-y[i][j])\n",
    "        a.append(proda)\n",
    "    return a\n",
    "\n",
    "def bi(beta,y):\n",
    "    b = []\n",
    "    for i in range(0,N):\n",
    "        prodb = 1\n",
    "        for j in range(0,R):\n",
    "            prodb = prodb*beta[j]**(1-y[i][j])*(1-beta[j])**(y[i][j])\n",
    "        b.append(prodb)\n",
    "    return b\n",
    "\n",
    "def pi(x,w):\n",
    "    p = []\n",
    "    for i in range(0,N):\n",
    "        p.append(sigma(x[i].dot(w.T)))\n",
    "    return p\n",
    "\n",
    "def mui(a,b,p):\n",
    "    mu = []\n",
    "    for i in range(0,N):\n",
    "        mu.append(a[i]*p[i]/(a[i]*p[i]+b[i]*(1-p[i])))\n",
    "    return mu\n",
    "\n",
    "def E_step(x,y,alpha,beta,w):\n",
    "    CE = 0 #Conditionnal excepectation\n",
    "    a = ai(alpha,y)\n",
    "    b = bi(beta,y)\n",
    "    p = pi(x,w)\n",
    "    mu = mui(a,b,p)\n",
    "    for i in range(0,N):\n",
    "        CE += mu[i]*np.log(p[i])*a[i]+(1-mu[i])*np.log(1-p[i])*b[i]\n",
    "    return mu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Log - Likelihood Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logLikelihood(w, y, alpha, beta):\n",
    "    a = ai(alpha, y)\n",
    "    b = bi(beta, y)\n",
    "    p = pi(x, w)\n",
    "    \n",
    "    #On calcule directement la log-vraissemblance.\n",
    "    vraissemblance = 0\n",
    "    for i in range(0,N):\n",
    "        vraissemblance = vraissemblance + np.log((a[i]*p[i])+b[i]*(1-p[i]))\n",
    "        \n",
    "    return vraissemblance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#M-step\n",
    "\n",
    "def alpha_function(mu,y):\n",
    "\talpha = []\n",
    "\tfor j in range(0,R):\n",
    "\t\ttmp1 = 0\n",
    "\t\ttmp2 = 0\n",
    "\t\tfor i in range(0,N):\n",
    "\t\t\ttmp1 += mu[i]*y[i][j]\n",
    "\t\t\ttmp2 += mu[i]\n",
    "\t\talpha.append(tmp1/tmp2)\n",
    "\treturn alpha\n",
    "\n",
    "def beta_function(mu,y):\n",
    "    beta = []\n",
    "    for j in range(0,R):\n",
    "        tmp1 = 0\n",
    "        tmp2 = 0\n",
    "        for i in range(0,N):\n",
    "            tmp1 += (1-mu[i])*(1-y[i][j])\n",
    "            tmp2 += 1-mu[i]\n",
    "        beta.append(tmp1/tmp2)\n",
    "    return beta\n",
    "\n",
    "def updateW(w,x, eta, mu):\n",
    "    g = 0\n",
    "    for i in range(0,N):\n",
    "        g += (mu[i] - sigma(x[i].dot(w.T)))*x[i]\n",
    "    \n",
    "    H = np.zeros((d,d))\n",
    "    for i in range(0,N):\n",
    "        H -= sigma(x[i].dot(w.T))*(1-sigma(x[i].dot(w.T)))*((x[i].reshape(d,1))*(x[i].reshape(1,d)))\n",
    "    w = w - eta*np.linalg.inv(H).dot(g)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0712328 ,  0.68627885,  0.17959314,  0.5280033 ,  0.18660934,\n",
       "         0.58655842,  0.8156623 ,  0.25828592,  0.80442013,  0.4460439 ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updateW(w0,x,0.01,mu0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00014573])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma(-x[0].dot(w0.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Itérations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION :  0\n",
      "Vraissemblance :  [-1538.17487312]\n",
      "Norme de diff_w :  0.07734278506\n",
      "Alpha :  [array([ 0.91308806]), array([ 0.69729888]), array([ 0.5371915]), array([ 0.47191632]), array([ 0.13052233])]\n",
      "Beta :  [array([ 0.1256996]), array([ 0.28960321]), array([ 0.53286485]), array([ 0.59151964]), array([ 0.88576052])]\n",
      "ITERATION :  100\n",
      "Vraissemblance :  [-1532.95810899]\n",
      "Norme de diff_w :  0.0206209972087\n",
      "Alpha :  [array([ 0.90177942]), array([ 0.65077594]), array([ 0.48379182]), array([ 0.41920836]), array([ 0.11272821])]\n",
      "Beta :  [array([ 0.11687485]), array([ 0.255507]), array([ 0.49264057]), array([ 0.55188947]), array([ 0.87244708])]\n",
      "ITERATION :  200\n",
      "Vraissemblance :  [-1532.87417577]\n",
      "Norme de diff_w :  0.0205847124017\n",
      "Alpha :  [array([ 0.90226257]), array([ 0.64992699]), array([ 0.48382694]), array([ 0.41883142]), array([ 0.11258126])]\n",
      "Beta :  [array([ 0.11722134]), array([ 0.25492741]), array([ 0.49267771]), array([ 0.55162603]), array([ 0.87234608])]\n",
      "ITERATION :  300\n",
      "Vraissemblance :  [-1532.78762791]\n",
      "Norme de diff_w :  0.020547580642\n",
      "Alpha :  [array([ 0.9027646]), array([ 0.64906953]), array([ 0.48387293]), array([ 0.41843496]), array([ 0.11243259])]\n",
      "Beta :  [array([ 0.11757975]), array([ 0.25434843]), array([ 0.49272409]), array([ 0.55135058]), array([ 0.87224493])]\n",
      "ITERATION :  400\n",
      "Vraissemblance :  [-1532.69828944]\n",
      "Norme de diff_w :  0.0205037884305\n",
      "Alpha :  [array([ 0.90328656]), array([ 0.64820339]), array([ 0.48392861]), array([ 0.41801673]), array([ 0.11228293])]\n",
      "Beta :  [array([ 0.11795063]), array([ 0.25377031]), array([ 0.49277885]), array([ 0.55106168]), array([ 0.87214423])]\n",
      "ITERATION :  500\n",
      "Vraissemblance :  [-1532.60600102]\n",
      "Norme de diff_w :  0.0204460356781\n",
      "Alpha :  [array([ 0.90382956]), array([ 0.64732855]), array([ 0.48399287]), array([ 0.41757496]), array([ 0.11213339])]\n",
      "Beta :  [array([ 0.11833454]), array([ 0.25319346]), array([ 0.49284114]), array([ 0.55075824]), array([ 0.87204485])]\n",
      "ITERATION :  600\n",
      "Vraissemblance :  [-1532.51062653]\n",
      "Norme de diff_w :  0.0203655776739\n",
      "Alpha :  [array([ 0.9043947]), array([ 0.64644515]), array([ 0.48406456]), array([ 0.41710845]), array([ 0.1119855])]\n",
      "Beta :  [array([ 0.11873203]), array([ 0.25261835]), array([ 0.49291009]), array([ 0.55043965]), array([ 0.87194798])]\n",
      "ITERATION :  700\n",
      "Vraissemblance :  [-1532.41205929]\n",
      "Norme de diff_w :  0.0202523521154\n",
      "Alpha :  [array([ 0.90498304]), array([ 0.64555356]), array([ 0.48414254]), array([ 0.41661664]), array([ 0.11184126])]\n",
      "Beta :  [array([ 0.11914362]), array([ 0.25204559]), array([ 0.49298483]), array([ 0.55010575]), array([ 0.87185512])]\n",
      "ITERATION :  800\n",
      "Vraissemblance :  [-1532.31022731]\n",
      "Norme de diff_w :  0.0200951969528\n",
      "Alpha :  [array([ 0.90559557]), array([ 0.64465431]), array([ 0.48422556]), array([ 0.41609964]), array([ 0.11170307])]\n",
      "Beta :  [array([ 0.11956975]), array([ 0.25147588]), array([ 0.4930644]), array([ 0.54975685]), array([ 0.87176804])]\n",
      "ITERATION :  900\n",
      "Vraissemblance :  [-1532.20509693]\n",
      "Norme de diff_w :  0.0198821525504\n",
      "Alpha :  [array([ 0.90623314]), array([ 0.64374818]), array([ 0.48431226]), array([ 0.41555815]), array([ 0.1115737])]\n",
      "Beta :  [array([ 0.12001076]), array([ 0.25091001]), array([ 0.49314774]), array([ 0.54939373]), array([ 0.87168877])]\n"
     ]
    }
   ],
   "source": [
    "mu = init_mu(y)\n",
    "alpha = alpha_function(mu,y)\n",
    "beta = beta_function(mu,y)\n",
    "diff_w = 10\n",
    "w = w0\n",
    "\n",
    "compteur = 0\n",
    "\n",
    "#while (np.linalg.norm(diff_w) > 0.001) : # Limite de convergence à decider\n",
    "while (compteur < 1000):\n",
    "    mu = E_step(x,y,alpha,beta,w)\n",
    "    alpha = alpha_function(mu,y)\n",
    "    beta = beta_function(mu,y)\n",
    "    w_bis = updateW(w,x,0.01,mu)\n",
    "    diff_w = w - w_bis\n",
    "    w = w_bis\n",
    "    if (compteur % 100 == 0):\n",
    "        print (\"ITERATION : \", compteur)\n",
    "        print(\"Vraissemblance : \", logLikelihood(w, y, alpha, beta))\n",
    "        print(\"Norme de diff_w : \", np.linalg.norm(diff_w))\n",
    "        print(\"Alpha : \", alpha)\n",
    "        print(\"Beta : \", beta)\n",
    "    compteur = compteur + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
