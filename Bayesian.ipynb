{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approche Bayésienne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aurianeblarre/miniconda3/lib/python3.4/site-packages/matplotlib/__init__.py:1350: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigma(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def logit(z):\n",
    "    return np.log(z/(1-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class model:\n",
    "    \"\"\"Classe qui encapsule l'apprentissage\"\"\"\n",
    "    \n",
    "    def __init__(self, D, R):\n",
    "        \"\"\"Constructeur\"\"\"\n",
    "        \n",
    "        self.D = D #Nombre de variables explicatives\n",
    "        self.R = R #Nombre d'annotateurs\n",
    "     \n",
    "    \n",
    "    def chargeData(self, path, recentrage = True):\n",
    "        \"\"\"Fonction qui charge les données avec path le chemin du fichier CSV. \n",
    "        Par défault, on impose un recentrage des donnée\"\"\"\n",
    "        \n",
    "        data = pd.read_csv(path, delimiter = \";\")\n",
    "        self.trueLabel = np.array(data.ix[:,self.D])\n",
    "        self.y = np.array(data.ix[:,self.D+1:]) #labels des annotateurs\n",
    "        x = np.array(data.ix[:,0:self.D]) #variables explicatives\n",
    "        if (recentrage):\n",
    "            self.x = (x -np.mean(x,axis=0))/(np.std(x, axis=0))\n",
    "        else:\n",
    "            self.x = x\n",
    "        self.N = self.y.shape[0] #Nombre de lignes\n",
    "     \n",
    "    def initPrior(self,mean_prior1, var_prior1, mean_prior2, var_prior2, gamma_prior):\n",
    "        \"\"\"Initialise les a priori sur alpha, beta, et gamma.\n",
    "        a est un tableau 2xR\n",
    "        b est un tableau 2xR\n",
    "        gamma_prior est une matrice de covariance DxD.\"\"\"\n",
    "        \n",
    "        self.a_prior = np.random.rand(2,self.R) \n",
    "        self.b_prior = np.random.rand(2,self.R)\n",
    "        for i in range(0,R):\n",
    "            self.a_prior[0][i] = (-mean_prior1[i]**3 + mean_prior1[i]**2 -mean_prior1[i]*var_prior1[i]**2)/var_prior1[i]**2\n",
    "            self.a_prior[1][i] = self.a_prior[0][i]*(1-mean_prior1[i])/mean_prior1[i]\n",
    "            self.b_prior[0][i] = (-mean_prior2[i]**3 + mean_prior2[i]**2 -mean_prior2[i]*var_prior2[i]**2)/var_prior2[i]**2\n",
    "            self.b_prior[1][i] = self.b_prior[0][i]*(1-mean_prior2[i])/mean_prior2[i]\n",
    "        \n",
    "        self.gamma_prior = gamma_prior\n",
    "    \n",
    "    def initMu(self):\n",
    "        \"\"\"Initialisation de mu\"\"\"\n",
    "        \n",
    "        self.mu = []\n",
    "        for i in range(0,self.N):\n",
    "            self.mu.append(np.sum(self.y[i])/self.R)\n",
    "    \n",
    "    \n",
    "    def ai(self):\n",
    "        \"\"\"Update du vecteur a (1xN)\"\"\"\n",
    "        \n",
    "        a = []\n",
    "        for i in range(0,self.N):\n",
    "            proda = 1\n",
    "            for j in range(0,self.R):\n",
    "                proda = proda*self.alpha[j]**(self.y[i][j])*(1-self.alpha[j])**(1-self.y[i][j])\n",
    "            a.append(proda)\n",
    "        self.a = a\n",
    "    \n",
    "    \n",
    "    def bi(self):\n",
    "        \"\"\"Update du vecteur b (1xN)\"\"\"\n",
    "        \n",
    "        b = []\n",
    "        for i in range(0,self.N):\n",
    "            prodb = 1\n",
    "            for j in range(0,self.R):\n",
    "                prodb = prodb*self.beta[j]**(1-self.y[i][j])*(1-self.beta[j])**(self.y[i][j])\n",
    "            b.append(prodb)\n",
    "        self.b = b\n",
    "       \n",
    "    \n",
    "    def pi(self):\n",
    "        \"\"\"Update du vecteur p (1xN)\"\"\"\n",
    "        \n",
    "        p = []\n",
    "        for i in range(0,self.N):\n",
    "            p.append(sigma(self.x[i].dot(self.w.T)))\n",
    "        self.p = p\n",
    "       \n",
    "    \n",
    "    def mui(self):\n",
    "        \"\"\"Update du vecteur mu (1xN). C'est l'étape E.\"\"\"\n",
    "        self.ai()\n",
    "        self.bi()\n",
    "        self.pi()\n",
    "        mu = []\n",
    "        for i in range(0,self.N):\n",
    "            mu.append(self.a[i]*self.p[i]/(self.a[i]*self.p[i]+self.b[i]*(1-self.p[i])))\n",
    "        self.mu = mu        \n",
    "      \n",
    "    \n",
    "    def logLikelihood(self):\n",
    "        \"\"\"Calcul de la log-vraissemblance.\"\"\"\n",
    "        \n",
    "        self.ai()\n",
    "        self.bi()\n",
    "        self.pi()\n",
    "    \n",
    "        #On calcule directement la log-vraissemblance.\n",
    "        vraissemblance = 0\n",
    "        for i in range(0,self.N):\n",
    "            vraissemblance = vraissemblance + np.log((self.a[i]*self.p[i])+self.b[i]*(1-self.p[i]))\n",
    "        return vraissemblance\n",
    "    \n",
    "    \n",
    "    def alphaUpdate(self):\n",
    "        \"\"\"Update du vecteur alpha sensitivity (1xR)\"\"\"\n",
    "        \n",
    "        alpha = []\n",
    "        for j in range(0,self.R):\n",
    "            tmp1 = 0\n",
    "            tmp2 = 0\n",
    "            for i in range(0,self.N):\n",
    "                tmp1 += self.mu[i]*self.y[i][j]\n",
    "                tmp2 += self.mu[i]\n",
    "            alpha.append((self.a_prior[0][j]-1+tmp1)/(self.a_prior[0][j]+self.a_prior[1][j]-2+tmp2))\n",
    "        self.alpha = alpha\n",
    "\n",
    "        \n",
    "    def betaUpdate(self):\n",
    "        \"\"\"Update du vecteur beta specificity (1xR)\"\"\"\n",
    "        \n",
    "        beta = []\n",
    "        for j in range(0,self.R):\n",
    "            tmp1 = 0\n",
    "            tmp2 = 0\n",
    "            for i in range(0,self.N):\n",
    "                tmp1 += (1-self.mu[i])*(1-self.y[i][j])\n",
    "                tmp2 += 1-self.mu[i]\n",
    "            beta.append((self.b_prior[0][j]-1+tmp1)/(self.b_prior[0][j]+self.b_prior[1][j]-2+tmp2))\n",
    "        self.beta = beta\n",
    "\n",
    "        \n",
    "    def wUpdate(self):\n",
    "        \"\"\"Update du vecteur poids w (1xR)\"\"\"\n",
    "        \n",
    "        g = 0\n",
    "        for i in range(0,self.N):\n",
    "            g += (self.mu[i] - sigma(self.x[i].dot(self.w.T)))*self.x[i]\n",
    "        tmp = np.reshape(-self.gamma_prior.dot(self.w.T),g.shape) # (11,1) -> (11,)\n",
    "        g += tmp\n",
    "    \n",
    "        H = np.zeros((self.D,self.D))\n",
    "        for i in range(0,self.N):\n",
    "            H -= sigma(self.x[i].dot(self.w.T))*(1-sigma(self.x[i].dot(self.w.T)))*((self.x[i].reshape(self.D,1))*(self.x[i].reshape(1,self.D)))\n",
    "        H -= self.gamma_prior\n",
    "        self.w = self.w - self.eta*np.linalg.inv(H).dot(g)\n",
    "    \n",
    "    \n",
    "    def score(self, seuil = 1/2):\n",
    "        \"\"\"Quel est le score d'apprentissage de notre modèle ?\"\"\"\n",
    "        return np.mean(np.equal(self.trueLabel, np.array(self.mu)>seuil))\n",
    "    \n",
    "    \n",
    "    def scoreMoy(self, seuil = 1/2):\n",
    "        \"\"\"Quel serait le score si on fesait naïvement la moyenne des avis des annotateurs ?\"\"\"\n",
    "        return np.mean(np.equal(self.trueLabel, np.mean(self.y, axis = 1)>seuil))\n",
    "\n",
    "    \n",
    "    def train(self, mean_prior1, var_prior1, mean_prior2, var_prior2, gamma_prior, maxIter = 1000, eta = 0.01, epsilon = 1e-10, graphe=True):\n",
    "        \"\"\"Fonction qui lance l'entrainement du modèle.\n",
    "        La variable graphe sert à plotter la log-likelihood au fil des itérations.\n",
    "        La log-likelihood devrait être croissante.\"\"\"\n",
    "        \n",
    "        self.maxIter = maxIter\n",
    "        self.eta = eta\n",
    "        \n",
    "        self.initPrior(mean_prior1, var_prior1, mean_prior2, var_prior2, gamma_prior)\n",
    "        self.initMu()\n",
    "        self.alphaUpdate()\n",
    "        self.betaUpdate()\n",
    "        self.w = np.random.rand(1,self.D)\n",
    "\n",
    "        compteur = 0\n",
    "        self.histLogLikelihood = []\n",
    "        \n",
    "        while (compteur < maxIter):\n",
    "            self.mui()\n",
    "            self.alphaUpdate()\n",
    "            self.betaUpdate()\n",
    "            wOld = self.w\n",
    "            self.wUpdate()\n",
    "            wNew = self.w\n",
    "            \n",
    "            self.histLogLikelihood.append(self.logLikelihood())\n",
    "            diffW = wOld - wNew\n",
    "            if (np.linalg.norm(diffW) < self.N*epsilon):\n",
    "                print(\"SEUIL DE CONVERGENCE SUR W ATTEINT\")\n",
    "                print (\"ITERATION : \", compteur)\n",
    "                print(\"Vraissemblance : \", self.logLikelihood())\n",
    "                print(\"Norme de diff_w : \", np.linalg.norm(diffW))\n",
    "                print(\"Alpha : \", self.alpha)\n",
    "                print(\"Beta : \", self.beta)\n",
    "                break\n",
    "            \n",
    "            if (compteur % 100 == 0):\n",
    "                print (\"ITERATION : \", compteur)\n",
    "                print(\"Vraissemblance : \", self.logLikelihood())\n",
    "                print(\"Norme de diff_w : \", np.linalg.norm(diffW))\n",
    "                print(\"Alpha : \", self.alpha)\n",
    "                print(\"Beta : \", self.beta)\n",
    "            compteur = compteur + 1\n",
    "        \n",
    "        if graphe:\n",
    "            plt.plot(self.histLogLikelihood)\n",
    "            plt.title('Log-vraissemblance au fil des itérations')\n",
    "\n",
    "    def roc(self) :\n",
    "        fpr, tpr, threshold = roc_curve(self.trueLabel, self.mu)\n",
    "        fpr1, tpr1, threshold1 = roc_curve(self.trueLabel, np.mean(self.y, axis = 1))\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        roc_auc1 = auc(fpr1, tpr1)\n",
    "        plt.plot(fpr, tpr, lw=1, label='ROC - AUC = %0.2f)'%(roc_auc))\n",
    "        plt.plot(fpr1, tpr1)\n",
    "        print(roc_auc, roc_auc1)\n",
    "    \n",
    "    def plot_alpha_beta(self) :\n",
    "        fpr, tpr, threshold = roc_curve(self.trueLabel, self.mu)\n",
    "        fpr1, tpr1, threshold1 = roc_curve(self.trueLabel, np.mean(self.y, axis = 1))\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        roc_auc1 = auc(fpr1, tpr1)\n",
    "        plt.plot(fpr, tpr, lw=1, label='ROC - AUC = %0.2f)'%(roc_auc))\n",
    "        plt.plot(fpr1, tpr1)\n",
    "        print(roc_auc, roc_auc1)\n",
    "    \n",
    "    def plot_alpha(self) :\n",
    "        fpr, tpr, threshold = roc_curve(self.trueLabel, self.mu)\n",
    "        fpr1, tpr1, threshold1 = roc_curve(self.trueLabel, np.mean(self.y, axis = 1))\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        roc_auc1 = auc(fpr1, tpr1)\n",
    "        plt.plot(fpr, tpr, lw=1, label='ROC - AUC = %0.2f)'%(roc_auc))\n",
    "        plt.plot(fpr1, tpr1)\n",
    "        print(roc_auc, roc_auc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Paramètres du data set\n",
    "D = 10\n",
    "R = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Nos hypothèses\n",
    "#Sensitivity\n",
    "mean_prior1 = np.array([0.9, 0.80, 0.57, 0.60, 0.55]) #Quel pourcentage de bonnes réponses l'expert donne en moyenne ?\n",
    "var_prior1 = np.array([1,1,1,1,1]) #Avec quelle incertitude ?\n",
    "\n",
    "#Sensibility\n",
    "mean_prior2 = np.array([0.95, 0.85, 0.62, 0.65, 0.58]) #Quel pourcentage de bonnes réponses l'expert donne en moyenne ?\n",
    "var_prior2 = np.array([1,1,1,1,1]) #Avec quelle incertitude ?\n",
    "\n",
    "#Weights\n",
    "gamma_prior = np.identity(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION :  0\n",
      "Vraissemblance :  [-1612.62129182]\n",
      "Norme de diff_w :  0.919393276119\n",
      "Alpha :  [array([ 0.80110216]), array([ 0.78960212]), array([ 0.62018791]), array([ 0.58701709]), array([ 0.53513987])]\n",
      "Beta :  [array([ 0.92673073]), array([ 0.84357514]), array([ 0.63887523]), array([ 0.62487875]), array([ 0.59194116])]\n",
      "SEUIL DE CONVERGENCE SUR W ATTEINT\n",
      "ITERATION :  27\n",
      "Vraissemblance :  [-1574.10218645]\n",
      "Norme de diff_w :  4.88231471188e-08\n",
      "Alpha :  [array([ 0.91325062]), array([ 0.85689453]), array([ 0.62936667]), array([ 0.5821661]), array([ 0.53121541])]\n",
      "Beta :  [array([ 0.95759023]), array([ 0.85205601]), array([ 0.63120648]), array([ 0.61110194]), array([ 0.58306268])]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEKCAYAAADn+anLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10337fb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "breast = model(D, R)\n",
    "breast.chargeData('Datasets/BreastCancer/DB_wdbc.csv')\n",
    "breast.train(mean_prior1, var_prior1, mean_prior2, var_prior2, gamma_prior,maxIter = 500, eta = 1, graphe = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "breast = model(D, R)\n",
    "breast.chargeData('Datasets/BreastCancer/DB_wdbcSparse.csv')\n",
    "breast.train(mean_prior1, var_prior1, mean_prior2, var_prior2, gamma_prior,maxIter = 500, eta = 1, graphe = True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "breast = model(D, R)\n",
    "breast.chargeData('Datasets/BreastCancer/DB_wdbc.csv')\n",
    "breast.train(mean_prior1, var_prior1, mean_prior2, var_prior2, gamma_prior,maxIter = 500, eta = 1, graphe = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LE SCORE D'ENTRAINEMENT EST DE :  0.651316001181\n",
      "LE SCORE NAIF DE MOYENNE DES ANNOTATEURS EST DE :  0.453654552879\n"
     ]
    }
   ],
   "source": [
    "print(\"LE SCORE D'ENTRAINEMENT EST DE : \", breast.score())\n",
    "print(\"LE SCORE NAIF DE MOYENNE DES ANNOTATEURS EST DE : \", breast.scoreMoy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.902644159727 0.422276306869\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEACAYAAABWLgY0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x271247c6908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "breast.roc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LE RESTE EST UN BROUILLON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wine = pd.read_csv('Datasets/whiteWine.csv', delimiter = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = 11  #descripteurs\n",
    "N =  wine.shape[0] #produits à tester\n",
    "R = 5 #experts\n",
    "\n",
    "y = np.array(wine.ix[:,d+2:]) #labels des annotateurs\n",
    "x = np.array(wine.ix[:,0:d]) #variables explicatives\n",
    "w0 = np.random.rand(1,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def init_mu(y):\n",
    "\tmu = []\n",
    "\tfor i in range(0,N):\n",
    "\t\tmu.append(np.sum(y[i])/R)\n",
    "\treturn mu\n",
    "\n",
    "mu0 = init_mu(y)\n",
    "\n",
    "def sigma(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def logit(z):\n",
    "    return np.log(z/(1-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Nos hypothèses\n",
    "#Sensitivity\n",
    "mean_prior1 = np.random.rand(R) #Quel pourcentage de bonnes réponses l'expert donne en moyenne ?\n",
    "var_prior1 = np.random.rand(R) #Avec quelle incertitude ?\n",
    "#Sensibility\n",
    "mean_prior2 = np.random.rand(R) #Quel pourcentage de bonnes réponses l'expert donne en moyenne ?\n",
    "var_prior2 = np.random.rand(R) #Avec quelle incertitude ?\n",
    "#Weights\n",
    "gamma_prior = np.random.rand(d,d)\n",
    "\n",
    "#On en déduit les paramètres \n",
    "a_prior = np.random.rand(2,R) \n",
    "b_prior = np.random.rand(2,R)\n",
    "for i in range(0,R):\n",
    "    a_prior[0][i] = (-mean_prior1[i]**3 + mean_prior1[i]**2 -mean_prior1[i]*var_prior1[i]**2)/var_prior1[i]**2\n",
    "    a_prior[1][i] = a_prior[0][i]*(1-mean_prior1[i])/mean_prior1[i]\n",
    "    b_prior[0][i] = (-mean_prior2[i]**3 + mean_prior2[i]**2 -mean_prior2[i]*var_prior2[i]**2)/var_prior2[i]**2\n",
    "    b_prior[1][i] = b_prior[0][i]*(1-mean_prior2[i])/mean_prior2[i]\n",
    "\n",
    "\n",
    "gamma_prior = np.linalg.inv(gamma_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#E-step\n",
    "\n",
    "def ai(alpha,y):\n",
    "    a = []\n",
    "    for i in range(0,N):\n",
    "        proda = 1\n",
    "        for j in range(0,R):\n",
    "            proda = proda*alpha[j]**(y[i][j])*(1-alpha[j])**(1-y[i][j])\n",
    "        a.append(proda)\n",
    "    return a\n",
    "\n",
    "def bi(beta,y):\n",
    "    b = []\n",
    "    for i in range(0,N):\n",
    "        prodb = 1\n",
    "        for j in range(0,R):\n",
    "            prodb = prodb*beta[j]**(1-y[i][j])*(1-beta[j])**(y[i][j])\n",
    "        b.append(prodb)\n",
    "    return b\n",
    "\n",
    "def pi(x,w):\n",
    "    p = []\n",
    "    for i in range(0,N):\n",
    "        p.append(sigma(x[i].dot(w.T)))\n",
    "    return p\n",
    "\n",
    "def mui(a,b,p):\n",
    "    mu = []\n",
    "    for i in range(0,N):\n",
    "        mu.append(a[i]*p[i]/(a[i]*p[i]+b[i]*(1-p[i])))\n",
    "    return mu\n",
    "\n",
    "def E_step(x,y,alpha,beta,w):\n",
    "    a = ai(alpha,y)\n",
    "    b = bi(beta,y)\n",
    "    p = pi(x,w)\n",
    "    mu = mui(a,b,p)\n",
    "    return mu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Log - Likelihood Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logLikelihood(w, y, alpha, beta):\n",
    "    a = ai(alpha, y)\n",
    "    b = bi(beta, y)\n",
    "    p = pi(x, w)\n",
    "    \n",
    "    #On calcule directement la log-vraissemblance.\n",
    "    vraissemblance = 0\n",
    "    for i in range(0,N):\n",
    "        vraissemblance = vraissemblance + np.log((a[i]*p[i])+b[i]*(1-p[i]))\n",
    "        \n",
    "    return vraissemblance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#M-step\n",
    "\n",
    "def alpha_function(mu,y,a_prior):\n",
    "\talpha = []\n",
    "\tfor j in range(0,R):\n",
    "\t\ttmp1 = 0\n",
    "\t\ttmp2 = 0\n",
    "\t\tfor i in range(0,N):\n",
    "\t\t\ttmp1 += mu[i]*y[i][j]\n",
    "\t\t\ttmp2 += mu[i]\n",
    "\t\talpha.append((a_prior[0][j]-1+tmp1)/(a_prior[0][j]+a_prior[1][j]-2+tmp2))\n",
    "\treturn alpha\n",
    "\n",
    "def beta_function(mu,y,b_prior):\n",
    "\tbeta = []\n",
    "\tfor j in range(0,R):\n",
    "\t\ttmp1 = 0\n",
    "\t\ttmp2 = 0\n",
    "\t\tfor i in range(0,N):\n",
    "\t\t\ttmp1 += (1-mu[i])*(1-y[i][j])\n",
    "\t\t\ttmp2 += 1-mu[i]\n",
    "\t\tbeta.append((b_prior[0][j]-1+tmp1)/(b_prior[0][j]+b_prior[1][j]-2+tmp2))\n",
    "\treturn beta\n",
    "\n",
    "def updateW(w,x, eta, mu, gamma_prior):\n",
    "    g = 0\n",
    "    for i in range(0,N):\n",
    "        g += (mu[i] - sigma(x[i].dot(w.T)))*x[i]\n",
    "    tmp = np.reshape(-gamma_prior.dot(w.T),g.shape) # (11,1) -> (11,)\n",
    "    g += tmp\n",
    "    \n",
    "    H = np.zeros((d,d))\n",
    "    for i in range(0,N):\n",
    "        H -= sigma(x[i].dot(w.T))*(1-sigma(x[i].dot(w.T)))*((x[i].reshape(11,1))*(x[i].reshape(1,11)))\n",
    "    H -= gamma_prior\n",
    "    w = w - eta*np.linalg.inv(H).dot(g)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-35334.92901159, -28871.41002449, -37022.64471383, -24159.64331136,\n",
       "        -33242.01854823, -20056.53651041, -34332.7256707 ,  -6830.87748493,\n",
       "        -27080.53161824, -13806.67227696, -20106.51189462]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updateW(w0,x,0.1,mu0,gamma_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Itérations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION :  0\n",
      "Vraissemblance :  [-12941.84181545]\n",
      "Norme de diff_w :  0.0189439655636\n",
      "Alpha :  [array([ 0.89419982]), array([ 0.70627847]), array([ 0.51154001]), array([ 0.40361302]), array([ 0.1026994])]\n",
      "Beta :  [array([ 0.4933009]), array([ 0.39185742]), array([ 0.55288447]), array([ 0.55593145]), array([ 0.84461565])]\n",
      "ITERATION :  10\n",
      "Vraissemblance :  [-12941.84181559]\n",
      "Norme de diff_w :  0.0171301718401\n",
      "Alpha :  [array([ 0.89419982]), array([ 0.70627847]), array([ 0.51154001]), array([ 0.40361302]), array([ 0.1026994])]\n",
      "Beta :  [array([ 0.49330092]), array([ 0.39185747]), array([ 0.55288447]), array([ 0.55593144]), array([ 0.84461576])]\n",
      "ITERATION :  20\n",
      "Vraissemblance :  [-12941.84181615]\n",
      "Norme de diff_w :  0.0154828695169\n",
      "Alpha :  [array([ 0.89419982]), array([ 0.70627847]), array([ 0.51154001]), array([ 0.40361302]), array([ 0.1026994])]\n",
      "Beta :  [array([ 0.49330103]), array([ 0.39185767]), array([ 0.55288445]), array([ 0.55593141]), array([ 0.84461627])]\n",
      "ITERATION :  30\n",
      "Vraissemblance :  [-12941.84181812]\n",
      "Norme de diff_w :  0.0139711304341\n",
      "Alpha :  [array([ 0.89419982]), array([ 0.70627847]), array([ 0.51154001]), array([ 0.40361302]), array([ 0.1026994])]\n",
      "Beta :  [array([ 0.49330142]), array([ 0.39185836]), array([ 0.55288442]), array([ 0.55593129]), array([ 0.84461821])]\n",
      "ITERATION :  40\n",
      "Vraissemblance :  [-12941.84182403]\n",
      "Norme de diff_w :  0.0125448593163\n",
      "Alpha :  [array([ 0.89419982]), array([ 0.70627847]), array([ 0.51154001]), array([ 0.40361302]), array([ 0.1026994])]\n",
      "Beta :  [array([ 0.49330257]), array([ 0.3918603]), array([ 0.55288443]), array([ 0.55593088]), array([ 0.84462474])]\n",
      "ITERATION :  50\n",
      "Vraissemblance :  [-12941.84183913]\n",
      "Norme de diff_w :  0.0111257616387\n",
      "Alpha :  [array([ 0.89419983]), array([ 0.70627847]), array([ 0.51154001]), array([ 0.40361301]), array([ 0.1026994])]\n",
      "Beta :  [array([ 0.49330552]), array([ 0.39186481]), array([ 0.5528848]), array([ 0.5559297]), array([ 0.84464394])]\n",
      "ITERATION :  60\n",
      "Vraissemblance :  [-12941.84187111]\n",
      "Norme de diff_w :  0.00964115269927\n",
      "Alpha :  [array([ 0.89419983]), array([ 0.70627847]), array([ 0.51154001]), array([ 0.40361301]), array([ 0.1026994])]\n",
      "Beta :  [array([ 0.49331172]), array([ 0.39187297]), array([ 0.55288661]), array([ 0.55592675]), array([ 0.84469191])]\n",
      "ITERATION :  70\n",
      "Vraissemblance :  [-12941.84192556]\n",
      "Norme de diff_w :  0.00813492985545\n",
      "Alpha :  [array([ 0.89419983]), array([ 0.70627847]), array([ 0.51154001]), array([ 0.40361299]), array([ 0.1026994])]\n",
      "Beta :  [array([ 0.49332217]), array([ 0.39188359]), array([ 0.55289192]), array([ 0.55592076]), array([ 0.84478952])]\n",
      "ITERATION :  80\n",
      "Vraissemblance :  [-12941.84200015]\n",
      "Norme de diff_w :  0.00678528456894\n",
      "Alpha :  [array([ 0.89419984]), array([ 0.70627847]), array([ 0.51154001]), array([ 0.40361297]), array([ 0.10269941])]\n",
      "Beta :  [array([ 0.49333627]), array([ 0.39189246]), array([ 0.55290288]), array([ 0.55591103]), array([ 0.84494825])]\n",
      "ITERATION :  90\n",
      "Vraissemblance :  [-12941.84208632]\n",
      "Norme de diff_w :  0.00571025943566\n",
      "Alpha :  [array([ 0.89419985]), array([ 0.70627848]), array([ 0.51154]), array([ 0.40361294]), array([ 0.10269941])]\n",
      "Beta :  [array([ 0.49335217]), array([ 0.39189524]), array([ 0.55292015]), array([ 0.55589791]), array([ 0.84516111])]\n"
     ]
    }
   ],
   "source": [
    "mu = init_mu(y)\n",
    "alpha = alpha_function(mu,y,a_prior)\n",
    "beta = beta_function(mu,y,b_prior)\n",
    "diff_w = 10\n",
    "w = w0\n",
    "\n",
    "compteur = 0\n",
    "\n",
    "#while (np.linalg.norm(diff_w) > 0.001) : # Limite de convergence à decider\n",
    "while (compteur < 100):\n",
    "    mu = E_step(x,y,alpha,beta,w)\n",
    "    alpha = alpha_function(mu,y,a_prior)\n",
    "    beta = beta_function(mu,y,b_prior)\n",
    "    w_bis = updateW(w,x,0.01,mu,gamma_prior)\n",
    "    diff_w = w - w_bis\n",
    "    w = w_bis\n",
    "    if (compteur % 10 == 0):\n",
    "        print (\"ITERATION : \", compteur)\n",
    "        print(\"Vraissemblance : \", logLikelihood(w, y, alpha, beta))\n",
    "        print(\"Norme de diff_w : \", np.linalg.norm(diff_w))\n",
    "        print(\"Alpha : \", alpha)\n",
    "        print(\"Beta : \", beta)\n",
    "    compteur = compteur + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.85478903e+00]\n",
      " [  2.78241174e-01]\n",
      " [  3.34191573e-01]\n",
      " [  6.39141613e+00]\n",
      " [  4.57723652e-02]\n",
      " [  3.53080920e+01]\n",
      " [  1.38360685e+02]\n",
      " [  9.94027574e-01]\n",
      " [  3.18826727e+00]\n",
      " [  4.89846974e-01]\n",
      " [  1.05142691e+01]] [[  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  1.85919375e-09]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [ -2.10763051e-07]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [ -3.53501284e-03]]\n"
     ]
    }
   ],
   "source": [
    "#weight of each expert\n",
    "weights = logit(np.array(alpha))+logit(np.array(beta))\n",
    "\n",
    "#Sensitivity and sensibility of classifiers\n",
    "alpha_clas = []\n",
    "beta_clas = []\n",
    "for j in range(0,d):\n",
    "    tmp = 0\n",
    "    tmp2 = 0\n",
    "    for i in range(0,N):\n",
    "        tmp += mu[j]*x[i][j]\n",
    "        tmp2 += (1-mu[j])*(1-x[i][j])\n",
    "    alpha_clas.append(tmp/np.sum(mu))\n",
    "    beta_clas.append(tmp2/(N-np.sum(mu)))\n",
    "alpha_clas = np.array(alpha_clas)\n",
    "beta_clas = np.array(beta_clas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class model:\n",
    "    \"\"\"Classe qui encapsule l'apprentissage\"\"\"\n",
    "    \n",
    "    def __init__(self, maxIter = 10000, eta = 0.01):\n",
    "        \"\"\"Constructeur\"\"\"\n",
    "        self.maxIter = maxIter\n",
    "        self.eta = eta\n",
    "        \n",
    "    def initMu(self, y):\n",
    "        \"\"\"Initialisation de mu\"\"\"\n",
    "        mu = []\n",
    "        for i in range(0,N):\n",
    "            mu.append(np.sum(y[i])/R)\n",
    "        return mu\n",
    "    \n",
    "    def ai(self, alpha, y):\n",
    "        \"\"\"Update du vecteur a (1xN)\"\"\"\n",
    "        a = []\n",
    "        for i in range(0,N):\n",
    "            proda = 1\n",
    "        for j in range(0,R):\n",
    "            proda = proda*alpha[j]**(y[i][j])*(1-alpha[j])**(1-y[i][j])\n",
    "            a.append(proda)\n",
    "        self.a = a\n",
    "        \n",
    "    def bi(self, beta, y):\n",
    "        \"\"\"Update du vecteur b (1xN)\"\"\"\n",
    "        b = []\n",
    "        for i in range(0,N):\n",
    "            prodb = 1\n",
    "        for j in range(0,R):\n",
    "            prodb = prodb*beta[j]**(1-y[i][j])*(1-beta[j])**(y[i][j])\n",
    "            b.append(prodb)\n",
    "        self.b = b\n",
    "        \n",
    "    def pi(self, x, w):\n",
    "        \"\"\"Update du vecteur p (1xN)\"\"\"\n",
    "        p = []\n",
    "        for i in range(0,N):\n",
    "            p.append(sigma(x[i].dot(w.T)))\n",
    "        self.p = p\n",
    "        \n",
    "    def mui(self, a,b,p):\n",
    "        \"\"\"Update de\"\"\"\n",
    "        mu = []\n",
    "        for i in range(0,N):\n",
    "            mu.append(a[i]*p[i]/(a[i]*p[i]+b[i]*(1-p[i])))\n",
    "        self.mu = mu\n",
    "    \n",
    "    def EStep(x,y,alpha,beta,w):\n",
    "        CE = 0 #Conditionnal excepectation\n",
    "        a = ai(alpha,y)\n",
    "        b = bi(beta,y)\n",
    "        p = pi(x,w)\n",
    "        mu = mui(a,b,p)\n",
    "        for i in range(0,N):\n",
    "            CE += mu[i]*np.log(p[i])*a[i]+(1-mu[i])*np.log(1-p[i])*b[i]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
