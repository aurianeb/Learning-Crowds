{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approche Bayésienne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srotc_000\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:1350: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigma(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def logit(z):\n",
    "    return np.log(z/(1-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class modelSparse:\n",
    "    \"\"\"Classe qui encapsule l'apprentissage\"\"\"\n",
    "    \n",
    "    def __init__(self, D, R):\n",
    "        \"\"\"Constructeur\"\"\"\n",
    "        \n",
    "        self.D = D #Nombre de variables explicatives\n",
    "        self.R = R #Nombre d'annotateurs\n",
    "     \n",
    "    \n",
    "    def chargeData(self, path, recentrage = True):\n",
    "        \"\"\"Fonction qui charge les données avec path le chemin du fichier CSV. \n",
    "        Par défault, on impose un recentrage des donnée\"\"\"\n",
    "        \n",
    "        data = pd.read_csv(path, delimiter = \";\")\n",
    "        self.trueLabel = np.array(data.ix[:,self.D])\n",
    "        self.y = np.array(data.ix[:,self.D+1:]) #labels des annotateurs\n",
    "        x = np.array(data.ix[:,0:self.D]) #variables explicatives\n",
    "        if (recentrage):\n",
    "            self.x = (x -np.mean(x,axis=0))/(np.std(x, axis=0))\n",
    "        else:\n",
    "            self.x = x\n",
    "        self.N = self.y.shape[0] #Nombre de lignes\n",
    "     \n",
    "    def initPrior(self,mean_prior1, var_prior1, mean_prior2, var_prior2, gamma_prior):\n",
    "        \"\"\"Initialise les a priori sur alpha, beta, et gamma.\n",
    "        a est un tableau 2xR\n",
    "        b est un tableau 2xR\n",
    "        gamma_prior est une matrice de covariance DxD.\"\"\"\n",
    "        \n",
    "        self.a_prior = np.random.rand(2,self.R) \n",
    "        self.b_prior = np.random.rand(2,self.R)\n",
    "        for i in range(0,R):\n",
    "            self.a_prior[0][i] = (-mean_prior1[i]**3 + mean_prior1[i]**2 -mean_prior1[i]*var_prior1[i]**2)/var_prior1[i]**2\n",
    "            self.a_prior[1][i] = self.a_prior[0][i]*(1-mean_prior1[i])/mean_prior1[i]\n",
    "            self.b_prior[0][i] = (-mean_prior2[i]**3 + mean_prior2[i]**2 -mean_prior2[i]*var_prior2[i]**2)/var_prior2[i]**2\n",
    "            self.b_prior[1][i] = self.b_prior[0][i]*(1-mean_prior2[i])/mean_prior2[i]\n",
    "        \n",
    "        self.gamma_prior = gamma_prior\n",
    "    \n",
    "    def initMu(self):\n",
    "        \"\"\"Initialisation de mu\"\"\"\n",
    "        \n",
    "        self.mu = []\n",
    "        for i in range(0,self.N):\n",
    "            self.mu.append(np.nansum(self.y[i])/self.R)\n",
    "    \n",
    "    \n",
    "    def ai(self):\n",
    "        \"\"\"Update du vecteur a (1xN)\"\"\"\n",
    "        \n",
    "        a = []\n",
    "        for i in range(0,self.N):\n",
    "            proda = 1\n",
    "            for j in range(0,self.R):\n",
    "                if (np.isnan(self.y[i][j])==False):\n",
    "                    proda = proda*self.alpha[j]**(self.y[i][j])*(1-self.alpha[j])**(1-self.y[i][j])\n",
    "            a.append(proda)\n",
    "        self.a = a\n",
    "    \n",
    "    \n",
    "    def bi(self):\n",
    "        \"\"\"Update du vecteur b (1xN)\"\"\"\n",
    "        \n",
    "        b = []\n",
    "        for i in range(0,self.N):\n",
    "            prodb = 1\n",
    "            for j in range(0,self.R):\n",
    "                if (np.isnan(self.y[i][j])==False):\n",
    "                    prodb = prodb*self.beta[j]**(1-self.y[i][j])*(1-self.beta[j])**(self.y[i][j])\n",
    "            b.append(prodb)\n",
    "        self.b = b\n",
    "       \n",
    "    \n",
    "    def pi(self):\n",
    "        \"\"\"Update du vecteur p (1xN)\"\"\"\n",
    "        \n",
    "        p = []\n",
    "        for i in range(0,self.N):\n",
    "            p.append(sigma(self.x[i].dot(self.w.T)))\n",
    "        self.p = p\n",
    "       \n",
    "    \n",
    "    def mui(self):\n",
    "        \"\"\"Update du vecteur mu (1xN). C'est l'étape E.\"\"\"\n",
    "        self.ai()\n",
    "        self.bi()\n",
    "        self.pi()\n",
    "        mu = []\n",
    "        for i in range(0,self.N):\n",
    "            mu.append(self.a[i]*self.p[i]/(self.a[i]*self.p[i]+self.b[i]*(1-self.p[i])))\n",
    "        self.mu = mu        \n",
    "      \n",
    "    \n",
    "    def logLikelihood(self):\n",
    "        \"\"\"Calcul de la log-vraissemblance.\"\"\"\n",
    "        \n",
    "        self.ai()\n",
    "        self.bi()\n",
    "        self.pi()\n",
    "    \n",
    "        #On calcule directement la log-vraissemblance.\n",
    "        vraissemblance = 0\n",
    "        for i in range(0,self.N):\n",
    "            vraissemblance = vraissemblance + np.log((self.a[i]*self.p[i])+self.b[i]*(1-self.p[i]))\n",
    "        return vraissemblance\n",
    "    \n",
    "    \n",
    "    def alphaUpdate(self):\n",
    "        \"\"\"Update du vecteur alpha sensitivity (1xR)\"\"\"\n",
    "        \n",
    "        alpha = []\n",
    "        for j in range(0,self.R):\n",
    "            tmp1 = 0\n",
    "            tmp2 = 0\n",
    "            for i in range(0,self.N):\n",
    "                if (np.isnan(self.y[i][j])==False):\n",
    "                    tmp1 += self.mu[i]*self.y[i][j]\n",
    "                    tmp2 += self.mu[i]\n",
    "            alpha.append((self.a_prior[0][j]-1+tmp1)/(self.a_prior[0][j]+self.a_prior[1][j]-2+tmp2))\n",
    "        self.alpha = alpha\n",
    "\n",
    "        \n",
    "    def betaUpdate(self):\n",
    "        \"\"\"Update du vecteur beta specificity (1xR)\"\"\"\n",
    "        \n",
    "        beta = []\n",
    "        for j in range(0,self.R):\n",
    "            tmp1 = 0\n",
    "            tmp2 = 0\n",
    "            for i in range(0,self.N):\n",
    "                if (np.isnan(self.y[i][j])==False):\n",
    "                    tmp1 += (1-self.mu[i])*(1-self.y[i][j])\n",
    "                    tmp2 += 1-self.mu[i]\n",
    "            beta.append((self.b_prior[0][j]-1+tmp1)/(self.b_prior[0][j]+self.b_prior[1][j]-2+tmp2))\n",
    "        self.beta = beta\n",
    "\n",
    "        \n",
    "    def wUpdate(self):\n",
    "        \"\"\"Update du vecteur poids w (1xR)\"\"\"\n",
    "        \n",
    "        g = 0\n",
    "        for i in range(0,self.N):\n",
    "            g += (self.mu[i] - sigma(self.x[i].dot(self.w.T)))*self.x[i]\n",
    "        tmp = np.reshape(-self.gamma_prior.dot(self.w.T),g.shape) # (11,1) -> (11,)\n",
    "        g += tmp\n",
    "    \n",
    "        H = np.zeros((self.D,self.D))\n",
    "        for i in range(0,self.N):\n",
    "            H -= sigma(self.x[i].dot(self.w.T))*(1-sigma(self.x[i].dot(self.w.T)))*((self.x[i].reshape(self.D,1))*(self.x[i].reshape(1,self.D)))\n",
    "        H -= self.gamma_prior\n",
    "        self.w = self.w - self.eta*np.linalg.inv(H).dot(g)\n",
    "    \n",
    "    \n",
    "    def score(self, seuil = 1/2):\n",
    "        \"\"\"Quel est le score d'apprentissage de notre modèle ?\"\"\"\n",
    "        return np.mean(np.equal(self.trueLabel, np.array(self.mu)>seuil))\n",
    "    \n",
    "    \n",
    "    def scoreMoy(self, seuil = 1/2):\n",
    "        \"\"\"Quel serait le score si on fesait naïvement la moyenne des avis des annotateurs ?\"\"\"\n",
    "        return np.mean(np.equal(self.trueLabel, np.nanmean(self.y, axis = 1)>seuil))\n",
    "\n",
    "    \n",
    "    def train(self, mean_prior1, var_prior1, mean_prior2, var_prior2, gamma_prior, maxIter = 1000, eta = 0.01, epsilon = 1e-10, graphe=True):\n",
    "        \"\"\"Fonction qui lance l'entrainement du modèle.\n",
    "        La variable graphe sert à plotter la log-likelihood au fil des itérations.\n",
    "        La log-likelihood devrait être croissante.\"\"\"\n",
    "        \n",
    "        self.maxIter = maxIter\n",
    "        self.eta = eta\n",
    "        \n",
    "        self.initPrior(mean_prior1, var_prior1, mean_prior2, var_prior2, gamma_prior)\n",
    "        self.initMu()\n",
    "        self.alphaUpdate()\n",
    "        self.betaUpdate()\n",
    "        self.w = np.random.rand(1,self.D)\n",
    "\n",
    "        compteur = 0\n",
    "        self.histLogLikelihood = []\n",
    "        \n",
    "        while (compteur < maxIter):\n",
    "            self.mui()\n",
    "            self.alphaUpdate()\n",
    "            self.betaUpdate()\n",
    "            wOld = self.w\n",
    "            self.wUpdate()\n",
    "            wNew = self.w\n",
    "            \n",
    "            self.histLogLikelihood.append(self.logLikelihood())\n",
    "            diffW = wOld - wNew\n",
    "            if (np.linalg.norm(diffW) < self.N*epsilon):\n",
    "                print(\"SEUIL DE CONVERGENCE SUR W ATTEINT\")\n",
    "                print (\"ITERATION : \", compteur)\n",
    "                print(\"Vraissemblance : \", self.logLikelihood())\n",
    "                print(\"Norme de diff_w : \", np.linalg.norm(diffW))\n",
    "                print(\"Alpha : \", self.alpha)\n",
    "                print(\"Beta : \", self.beta)\n",
    "                break\n",
    "            \n",
    "            if (compteur % 100 == 0):\n",
    "                print (\"ITERATION : \", compteur)\n",
    "                print(\"Vraissemblance : \", self.logLikelihood())\n",
    "                print(\"Norme de diff_w : \", np.linalg.norm(diffW))\n",
    "                print(\"Alpha : \", self.alpha)\n",
    "                print(\"Beta : \", self.beta)\n",
    "            compteur = compteur + 1\n",
    "        \n",
    "        if graphe:\n",
    "            plt.plot(self.histLogLikelihood)\n",
    "            plt.title('Log-vraissemblance au fil des itérations')\n",
    "\n",
    "    def roc(self) :\n",
    "        falsePR, truePR, threshold = roc_curve(self.trueLabel, self.mu) #falsePositiveRate and truePositiveRate\n",
    "        falsePR1, truePR1, threshold1 = roc_curve(self.trueLabel, np.nanmean(self.y, axis = 1))\n",
    "        roc_auc = auc(falsePR, truePR)\n",
    "        roc_auc1 = auc(falsePR1, truePR1)\n",
    "        plt.plot(falsePR, truePR, lw=2, label='ROC - AUC = %0.2f)'%(roc_auc))\n",
    "        plt.plot(falsePR1, truePR1, lw = 2, label = 'ROC - AUC = %0.2f)'%(roc_auc1))\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Paramètres du data set\n",
    "D = 11\n",
    "R = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Nos hypothèses\n",
    "#Sensitivity\n",
    "mean_prior1 = np.array([0.9, 0.8, 0.4, 0.2, 0.1]) #Quel pourcentage de bonnes réponses l'expert donne en moyenne ?\n",
    "var_prior1 = np.array([1,1,1,1,1]) #Avec quelle incertitude ?\n",
    "\n",
    "#Sensibility\n",
    "mean_prior2 = np.array([0.85, 0.75, 0.45, 0.25, 0.1]) #Quel pourcentage de bonnes réponses l'expert donne en moyenne ?\n",
    "var_prior2 = np.array([1,1,1,1,1]) #Avec quelle incertitude ?\n",
    "\n",
    "#Weights\n",
    "gamma_prior = np.identity(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION :  0\n",
      "Vraissemblance :  [-115.30378142]\n",
      "Norme de diff_w :  4.76979438734\n",
      "Alpha :  [array([ 1.00841474]), array([ 1.00983651]), array([ 1.01500783]), array([ 1.01846381]), array([-0.00838278])]\n",
      "Beta :  [array([ 1.01699751]), array([ 1.01822961]), array([ 1.02148134]), array([ 1.02526885]), array([-0.01603892])]\n",
      "SEUIL DE CONVERGENCE SUR W ATTEINT\n",
      "ITERATION :  12\n",
      "Vraissemblance :  [-36.86423011]\n",
      "Norme de diff_w :  1.20202714033e-10\n",
      "Alpha :  [array([-0.0313135]), array([-0.02874835]), array([-0.0220122]), array([-0.02008254]), array([ 1.03078357])]\n",
      "Beta :  [array([-0.03048622]), array([-0.02813985]), array([-0.02338129]), array([-0.02103782]), array([ 1.03186154])]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEKCAYAAADw2zkCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZmaGk4GZmQH/H/yI/nDTRkPcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2652f393c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "breast = modelSparse(D, R)\n",
    "breast.chargeData('Datasets/DebugBis.csv')\n",
    "breast.train(mean_prior1, var_prior1, mean_prior2, var_prior2, gamma_prior,maxIter = 500, eta = 1, graphe = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LE SCORE D'ENTRAINEMENT EST DE :  0.499702558001\n",
      "LE SCORE NAIF DE MOYENNE DES ANNOTATEURS EST DE :  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"LE SCORE D'ENTRAINEMENT EST DE : \", breast.score())\n",
    "print(\"LE SCORE NAIF DE MOYENNE DES ANNOTATEURS EST DE : \", breast.scoreMoy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEACAYAAABWLgY0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2652f4625c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "breast.roc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LE RESTE EST UN BROUILLON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wine = pd.read_csv('Datasets/whiteWine.csv', delimiter = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = 11  #descripteurs\n",
    "N =  wine.shape[0] #produits à tester\n",
    "R = 5 #experts\n",
    "\n",
    "y = np.array(wine.ix[:,d+2:]) #labels des annotateurs\n",
    "x = np.array(wine.ix[:,0:d]) #variables explicatives\n",
    "w0 = np.random.rand(1,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def init_mu(y):\n",
    "\tmu = []\n",
    "\tfor i in range(0,N):\n",
    "\t\tmu.append(np.sum(y[i])/R)\n",
    "\treturn mu\n",
    "\n",
    "mu0 = init_mu(y)\n",
    "\n",
    "def sigma(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def logit(z):\n",
    "    return np.log(z/(1-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Nos hypothèses\n",
    "#Sensitivity\n",
    "mean_prior1 = np.random.rand(R) #Quel pourcentage de bonnes réponses l'expert donne en moyenne ?\n",
    "var_prior1 = np.random.rand(R) #Avec quelle incertitude ?\n",
    "#Sensibility\n",
    "mean_prior2 = np.random.rand(R) #Quel pourcentage de bonnes réponses l'expert donne en moyenne ?\n",
    "var_prior2 = np.random.rand(R) #Avec quelle incertitude ?\n",
    "#Weights\n",
    "gamma_prior = np.random.rand(d,d)\n",
    "\n",
    "#On en déduit les paramètres \n",
    "a_prior = np.random.rand(2,R) \n",
    "b_prior = np.random.rand(2,R)\n",
    "for i in range(0,R):\n",
    "    a_prior[0][i] = (-mean_prior1[i]**3 + mean_prior1[i]**2 -mean_prior1[i]*var_prior1[i]**2)/var_prior1[i]**2\n",
    "    a_prior[1][i] = a_prior[0][i]*(1-mean_prior1[i])/mean_prior1[i]\n",
    "    b_prior[0][i] = (-mean_prior2[i]**3 + mean_prior2[i]**2 -mean_prior2[i]*var_prior2[i]**2)/var_prior2[i]**2\n",
    "    b_prior[1][i] = b_prior[0][i]*(1-mean_prior2[i])/mean_prior2[i]\n",
    "\n",
    "\n",
    "gamma_prior = np.linalg.inv(gamma_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#E-step\n",
    "\n",
    "def ai(alpha,y):\n",
    "    a = []\n",
    "    for i in range(0,N):\n",
    "        proda = 1\n",
    "        for j in range(0,R):\n",
    "            proda = proda*alpha[j]**(y[i][j])*(1-alpha[j])**(1-y[i][j])\n",
    "        a.append(proda)\n",
    "    return a\n",
    "\n",
    "def bi(beta,y):\n",
    "    b = []\n",
    "    for i in range(0,N):\n",
    "        prodb = 1\n",
    "        for j in range(0,R):\n",
    "            prodb = prodb*beta[j]**(1-y[i][j])*(1-beta[j])**(y[i][j])\n",
    "        b.append(prodb)\n",
    "    return b\n",
    "\n",
    "def pi(x,w):\n",
    "    p = []\n",
    "    for i in range(0,N):\n",
    "        p.append(sigma(x[i].dot(w.T)))\n",
    "    return p\n",
    "\n",
    "def mui(a,b,p):\n",
    "    mu = []\n",
    "    for i in range(0,N):\n",
    "        mu.append(a[i]*p[i]/(a[i]*p[i]+b[i]*(1-p[i])))\n",
    "    return mu\n",
    "\n",
    "def E_step(x,y,alpha,beta,w):\n",
    "    a = ai(alpha,y)\n",
    "    b = bi(beta,y)\n",
    "    p = pi(x,w)\n",
    "    mu = mui(a,b,p)\n",
    "    return mu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Log - Likelihood Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logLikelihood(w, y, alpha, beta):\n",
    "    a = ai(alpha, y)\n",
    "    b = bi(beta, y)\n",
    "    p = pi(x, w)\n",
    "    \n",
    "    #On calcule directement la log-vraissemblance.\n",
    "    vraissemblance = 0\n",
    "    for i in range(0,N):\n",
    "        vraissemblance = vraissemblance + np.log((a[i]*p[i])+b[i]*(1-p[i]))\n",
    "        \n",
    "    return vraissemblance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#M-step\n",
    "\n",
    "def alpha_function(mu,y,a_prior):\n",
    "\talpha = []\n",
    "\tfor j in range(0,R):\n",
    "\t\ttmp1 = 0\n",
    "\t\ttmp2 = 0\n",
    "\t\tfor i in range(0,N):\n",
    "\t\t\ttmp1 += mu[i]*y[i][j]\n",
    "\t\t\ttmp2 += mu[i]\n",
    "\t\talpha.append((a_prior[0][j]-1+tmp1)/(a_prior[0][j]+a_prior[1][j]-2+tmp2))\n",
    "\treturn alpha\n",
    "\n",
    "def beta_function(mu,y,b_prior):\n",
    "\tbeta = []\n",
    "\tfor j in range(0,R):\n",
    "\t\ttmp1 = 0\n",
    "\t\ttmp2 = 0\n",
    "\t\tfor i in range(0,N):\n",
    "\t\t\ttmp1 += (1-mu[i])*(1-y[i][j])\n",
    "\t\t\ttmp2 += 1-mu[i]\n",
    "\t\tbeta.append((b_prior[0][j]-1+tmp1)/(b_prior[0][j]+b_prior[1][j]-2+tmp2))\n",
    "\treturn beta\n",
    "\n",
    "def updateW(w,x, eta, mu, gamma_prior):\n",
    "    g = 0\n",
    "    for i in range(0,N):\n",
    "        g += (mu[i] - sigma(x[i].dot(w.T)))*x[i]\n",
    "    tmp = np.reshape(-gamma_prior.dot(w.T),g.shape) # (11,1) -> (11,)\n",
    "    g += tmp\n",
    "    \n",
    "    H = np.zeros((d,d))\n",
    "    for i in range(0,N):\n",
    "        H -= sigma(x[i].dot(w.T))*(1-sigma(x[i].dot(w.T)))*((x[i].reshape(11,1))*(x[i].reshape(1,11)))\n",
    "    H -= gamma_prior\n",
    "    w = w - eta*np.linalg.inv(H).dot(g)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-35334.92901159, -28871.41002449, -37022.64471383, -24159.64331136,\n",
       "        -33242.01854823, -20056.53651041, -34332.7256707 ,  -6830.87748493,\n",
       "        -27080.53161824, -13806.67227696, -20106.51189462]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updateW(w0,x,0.1,mu0,gamma_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Itérations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION :  0\n",
      "Vraissemblance :  [-12941.84181545]\n",
      "Norme de diff_w :  0.0189439655636\n",
      "Alpha :  [array([ 0.89419982]), array([ 0.70627847]), array([ 0.51154001]), array([ 0.40361302]), array([ 0.1026994])]\n",
      "Beta :  [array([ 0.4933009]), array([ 0.39185742]), array([ 0.55288447]), array([ 0.55593145]), array([ 0.84461565])]\n",
      "ITERATION :  10\n",
      "Vraissemblance :  [-12941.84181559]\n",
      "Norme de diff_w :  0.0171301718401\n",
      "Alpha :  [array([ 0.89419982]), array([ 0.70627847]), array([ 0.51154001]), array([ 0.40361302]), array([ 0.1026994])]\n",
      "Beta :  [array([ 0.49330092]), array([ 0.39185747]), array([ 0.55288447]), array([ 0.55593144]), array([ 0.84461576])]\n",
      "ITERATION :  20\n",
      "Vraissemblance :  [-12941.84181615]\n",
      "Norme de diff_w :  0.0154828695169\n",
      "Alpha :  [array([ 0.89419982]), array([ 0.70627847]), array([ 0.51154001]), array([ 0.40361302]), array([ 0.1026994])]\n",
      "Beta :  [array([ 0.49330103]), array([ 0.39185767]), array([ 0.55288445]), array([ 0.55593141]), array([ 0.84461627])]\n",
      "ITERATION :  30\n",
      "Vraissemblance :  [-12941.84181812]\n",
      "Norme de diff_w :  0.0139711304341\n",
      "Alpha :  [array([ 0.89419982]), array([ 0.70627847]), array([ 0.51154001]), array([ 0.40361302]), array([ 0.1026994])]\n",
      "Beta :  [array([ 0.49330142]), array([ 0.39185836]), array([ 0.55288442]), array([ 0.55593129]), array([ 0.84461821])]\n",
      "ITERATION :  40\n",
      "Vraissemblance :  [-12941.84182403]\n",
      "Norme de diff_w :  0.0125448593163\n",
      "Alpha :  [array([ 0.89419982]), array([ 0.70627847]), array([ 0.51154001]), array([ 0.40361302]), array([ 0.1026994])]\n",
      "Beta :  [array([ 0.49330257]), array([ 0.3918603]), array([ 0.55288443]), array([ 0.55593088]), array([ 0.84462474])]\n",
      "ITERATION :  50\n",
      "Vraissemblance :  [-12941.84183913]\n",
      "Norme de diff_w :  0.0111257616387\n",
      "Alpha :  [array([ 0.89419983]), array([ 0.70627847]), array([ 0.51154001]), array([ 0.40361301]), array([ 0.1026994])]\n",
      "Beta :  [array([ 0.49330552]), array([ 0.39186481]), array([ 0.5528848]), array([ 0.5559297]), array([ 0.84464394])]\n",
      "ITERATION :  60\n",
      "Vraissemblance :  [-12941.84187111]\n",
      "Norme de diff_w :  0.00964115269927\n",
      "Alpha :  [array([ 0.89419983]), array([ 0.70627847]), array([ 0.51154001]), array([ 0.40361301]), array([ 0.1026994])]\n",
      "Beta :  [array([ 0.49331172]), array([ 0.39187297]), array([ 0.55288661]), array([ 0.55592675]), array([ 0.84469191])]\n",
      "ITERATION :  70\n",
      "Vraissemblance :  [-12941.84192556]\n",
      "Norme de diff_w :  0.00813492985545\n",
      "Alpha :  [array([ 0.89419983]), array([ 0.70627847]), array([ 0.51154001]), array([ 0.40361299]), array([ 0.1026994])]\n",
      "Beta :  [array([ 0.49332217]), array([ 0.39188359]), array([ 0.55289192]), array([ 0.55592076]), array([ 0.84478952])]\n",
      "ITERATION :  80\n",
      "Vraissemblance :  [-12941.84200015]\n",
      "Norme de diff_w :  0.00678528456894\n",
      "Alpha :  [array([ 0.89419984]), array([ 0.70627847]), array([ 0.51154001]), array([ 0.40361297]), array([ 0.10269941])]\n",
      "Beta :  [array([ 0.49333627]), array([ 0.39189246]), array([ 0.55290288]), array([ 0.55591103]), array([ 0.84494825])]\n",
      "ITERATION :  90\n",
      "Vraissemblance :  [-12941.84208632]\n",
      "Norme de diff_w :  0.00571025943566\n",
      "Alpha :  [array([ 0.89419985]), array([ 0.70627848]), array([ 0.51154]), array([ 0.40361294]), array([ 0.10269941])]\n",
      "Beta :  [array([ 0.49335217]), array([ 0.39189524]), array([ 0.55292015]), array([ 0.55589791]), array([ 0.84516111])]\n"
     ]
    }
   ],
   "source": [
    "mu = init_mu(y)\n",
    "alpha = alpha_function(mu,y,a_prior)\n",
    "beta = beta_function(mu,y,b_prior)\n",
    "diff_w = 10\n",
    "w = w0\n",
    "\n",
    "compteur = 0\n",
    "\n",
    "#while (np.linalg.norm(diff_w) > 0.001) : # Limite de convergence à decider\n",
    "while (compteur < 100):\n",
    "    mu = E_step(x,y,alpha,beta,w)\n",
    "    alpha = alpha_function(mu,y,a_prior)\n",
    "    beta = beta_function(mu,y,b_prior)\n",
    "    w_bis = updateW(w,x,0.01,mu,gamma_prior)\n",
    "    diff_w = w - w_bis\n",
    "    w = w_bis\n",
    "    if (compteur % 10 == 0):\n",
    "        print (\"ITERATION : \", compteur)\n",
    "        print(\"Vraissemblance : \", logLikelihood(w, y, alpha, beta))\n",
    "        print(\"Norme de diff_w : \", np.linalg.norm(diff_w))\n",
    "        print(\"Alpha : \", alpha)\n",
    "        print(\"Beta : \", beta)\n",
    "    compteur = compteur + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.85478903e+00]\n",
      " [  2.78241174e-01]\n",
      " [  3.34191573e-01]\n",
      " [  6.39141613e+00]\n",
      " [  4.57723652e-02]\n",
      " [  3.53080920e+01]\n",
      " [  1.38360685e+02]\n",
      " [  9.94027574e-01]\n",
      " [  3.18826727e+00]\n",
      " [  4.89846974e-01]\n",
      " [  1.05142691e+01]] [[  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  1.85919375e-09]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [ -2.10763051e-07]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [ -3.53501284e-03]]\n"
     ]
    }
   ],
   "source": [
    "#weight of each expert\n",
    "weights = logit(np.array(alpha))+logit(np.array(beta))\n",
    "\n",
    "#Sensitivity and sensibility of classifiers\n",
    "alpha_clas = []\n",
    "beta_clas = []\n",
    "for j in range(0,d):\n",
    "    tmp = 0\n",
    "    tmp2 = 0\n",
    "    for i in range(0,N):\n",
    "        tmp += mu[j]*x[i][j]\n",
    "        tmp2 += (1-mu[j])*(1-x[i][j])\n",
    "    alpha_clas.append(tmp/np.sum(mu))\n",
    "    beta_clas.append(tmp2/(N-np.sum(mu)))\n",
    "alpha_clas = np.array(alpha_clas)\n",
    "beta_clas = np.array(beta_clas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class model:\n",
    "    \"\"\"Classe qui encapsule l'apprentissage\"\"\"\n",
    "    \n",
    "    def __init__(self, maxIter = 10000, eta = 0.01):\n",
    "        \"\"\"Constructeur\"\"\"\n",
    "        self.maxIter = maxIter\n",
    "        self.eta = eta\n",
    "        \n",
    "    def initMu(self, y):\n",
    "        \"\"\"Initialisation de mu\"\"\"\n",
    "        mu = []\n",
    "        for i in range(0,N):\n",
    "            mu.append(np.sum(y[i])/R)\n",
    "        return mu\n",
    "    \n",
    "    def ai(self, alpha, y):\n",
    "        \"\"\"Update du vecteur a (1xN)\"\"\"\n",
    "        a = []\n",
    "        for i in range(0,N):\n",
    "            proda = 1\n",
    "        for j in range(0,R):\n",
    "            proda = proda*alpha[j]**(y[i][j])*(1-alpha[j])**(1-y[i][j])\n",
    "            a.append(proda)\n",
    "        self.a = a\n",
    "        \n",
    "    def bi(self, beta, y):\n",
    "        \"\"\"Update du vecteur b (1xN)\"\"\"\n",
    "        b = []\n",
    "        for i in range(0,N):\n",
    "            prodb = 1\n",
    "        for j in range(0,R):\n",
    "            prodb = prodb*beta[j]**(1-y[i][j])*(1-beta[j])**(y[i][j])\n",
    "            b.append(prodb)\n",
    "        self.b = b\n",
    "        \n",
    "    def pi(self, x, w):\n",
    "        \"\"\"Update du vecteur p (1xN)\"\"\"\n",
    "        p = []\n",
    "        for i in range(0,N):\n",
    "            p.append(sigma(x[i].dot(w.T)))\n",
    "        self.p = p\n",
    "        \n",
    "    def mui(self, a,b,p):\n",
    "        \"\"\"Update de\"\"\"\n",
    "        mu = []\n",
    "        for i in range(0,N):\n",
    "            mu.append(a[i]*p[i]/(a[i]*p[i]+b[i]*(1-p[i])))\n",
    "        self.mu = mu\n",
    "    \n",
    "    def EStep(x,y,alpha,beta,w):\n",
    "        CE = 0 #Conditionnal excepectation\n",
    "        a = ai(alpha,y)\n",
    "        b = bi(beta,y)\n",
    "        p = pi(x,w)\n",
    "        mu = mui(a,b,p)\n",
    "        for i in range(0,N):\n",
    "            CE += mu[i]*np.log(p[i])*a[i]+(1-mu[i])*np.log(1-p[i])*b[i]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
