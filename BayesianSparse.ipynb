{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approche Bayésienne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aurianeblarre/miniconda3/lib/python3.4/site-packages/matplotlib/__init__.py:1350: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigma(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def logit(z):\n",
    "    return np.log(z/(1-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class modelSparse:\n",
    "    \"\"\"Classe qui encapsule l'apprentissage\"\"\"\n",
    "    \n",
    "    def __init__(self, D, R):\n",
    "        \"\"\"Constructeur\"\"\"\n",
    "        \n",
    "        self.D = D #Nombre de variables explicatives\n",
    "        self.R = R #Nombre d'annotateurs\n",
    "     \n",
    "    \n",
    "    def chargeData(self, path, recentrage = True):\n",
    "        \"\"\"Fonction qui charge les données avec path le chemin du fichier CSV. \n",
    "        Par défault, on impose un recentrage des donnée\"\"\"\n",
    "        \n",
    "        data = pd.read_csv(path, delimiter = \";\")\n",
    "        self.trueLabel = np.array(data.ix[:,self.D])\n",
    "        self.y = np.array(data.ix[:,self.D+1:]) #labels des annotateurs\n",
    "        x = np.array(data.ix[:,0:self.D]) #variables explicatives\n",
    "        if (recentrage):\n",
    "            self.x = (x -np.mean(x,axis=0))/(np.std(x, axis=0))\n",
    "        else:\n",
    "            self.x = x\n",
    "        self.N = self.y.shape[0] #Nombre de lignes\n",
    "     \n",
    "    def initPrior(self,mean_prior1, var_prior1, mean_prior2, var_prior2, gamma_prior):\n",
    "        \"\"\"Initialise les a priori sur alpha, beta, et gamma.\n",
    "        a est un tableau 2xR\n",
    "        b est un tableau 2xR\n",
    "        gamma_prior est une matrice de covariance DxD.\"\"\"\n",
    "        \n",
    "        self.a_prior = np.random.rand(2,self.R) \n",
    "        self.b_prior = np.random.rand(2,self.R)\n",
    "        for i in range(0,R):\n",
    "            self.a_prior[0][i] = (-mean_prior1[i]**3 + mean_prior1[i]**2 -mean_prior1[i]*var_prior1[i]**2)/var_prior1[i]**2\n",
    "            self.a_prior[1][i] = self.a_prior[0][i]*(1-mean_prior1[i])/mean_prior1[i]\n",
    "            self.b_prior[0][i] = (-mean_prior2[i]**3 + mean_prior2[i]**2 -mean_prior2[i]*var_prior2[i]**2)/var_prior2[i]**2\n",
    "            self.b_prior[1][i] = self.b_prior[0][i]*(1-mean_prior2[i])/mean_prior2[i]\n",
    "        \n",
    "        self.gamma_prior = gamma_prior\n",
    "    \n",
    "    def initMu(self):\n",
    "        \"\"\"Initialisation de mu\"\"\"\n",
    "        \n",
    "        self.mu = []\n",
    "        for i in range(0,self.N):\n",
    "            self.mu.append(np.nansum(self.y[i])/self.R)\n",
    "    \n",
    "    \n",
    "    def ai(self):\n",
    "        \"\"\"Update du vecteur a (1xN)\"\"\"\n",
    "        \n",
    "        a = []\n",
    "        for i in range(0,self.N):\n",
    "            proda = 1\n",
    "            for j in range(0,self.R):\n",
    "                if (np.isnan(self.y[i][j])==False):\n",
    "                    proda = proda*self.alpha[j]**(self.y[i][j])*(1-self.alpha[j])**(1-self.y[i][j])\n",
    "            a.append(proda)\n",
    "        self.a = a\n",
    "    \n",
    "    \n",
    "    def bi(self):\n",
    "        \"\"\"Update du vecteur b (1xN)\"\"\"\n",
    "        \n",
    "        b = []\n",
    "        for i in range(0,self.N):\n",
    "            prodb = 1\n",
    "            for j in range(0,self.R):\n",
    "                if (np.isnan(self.y[i][j])==False):\n",
    "                    prodb = prodb*self.beta[j]**(1-self.y[i][j])*(1-self.beta[j])**(self.y[i][j])\n",
    "            b.append(prodb)\n",
    "        self.b = b\n",
    "       \n",
    "    \n",
    "    def pi(self):\n",
    "        \"\"\"Update du vecteur p (1xN)\"\"\"\n",
    "        \n",
    "        p = []\n",
    "        for i in range(0,self.N):\n",
    "            p.append(sigma(self.x[i].dot(self.w.T)))\n",
    "        self.p = p\n",
    "       \n",
    "    \n",
    "    def mui(self):\n",
    "        \"\"\"Update du vecteur mu (1xN). C'est l'étape E.\"\"\"\n",
    "        self.ai()\n",
    "        self.bi()\n",
    "        self.pi()\n",
    "        mu = []\n",
    "        for i in range(0,self.N):\n",
    "            mu.append(self.a[i]*self.p[i]/(self.a[i]*self.p[i]+self.b[i]*(1-self.p[i])))\n",
    "        self.mu = mu        \n",
    "      \n",
    "    \n",
    "    def logLikelihood(self):\n",
    "        \"\"\"Calcul de la log-vraissemblance.\"\"\"\n",
    "        \n",
    "        self.ai()\n",
    "        self.bi()\n",
    "        self.pi()\n",
    "    \n",
    "        #On calcule directement la log-vraissemblance.\n",
    "        vraissemblance = 0\n",
    "        for i in range(0,self.N):\n",
    "            vraissemblance = vraissemblance + np.log((self.a[i]*self.p[i])+self.b[i]*(1-self.p[i]))\n",
    "        return vraissemblance\n",
    "    \n",
    "    \n",
    "    def alphaUpdate(self):\n",
    "        \"\"\"Update du vecteur alpha sensitivity (1xR)\"\"\"\n",
    "        \n",
    "        alpha = []\n",
    "        for j in range(0,self.R):\n",
    "            tmp1 = 0\n",
    "            tmp2 = 0\n",
    "            for i in range(0,self.N):\n",
    "                if (np.isnan(self.y[i][j])==False):\n",
    "                    tmp1 += self.mu[i]*self.y[i][j]\n",
    "                    tmp2 += self.mu[i]\n",
    "            alpha.append((self.a_prior[0][j]-1+tmp1)/(self.a_prior[0][j]+self.a_prior[1][j]-2+tmp2))\n",
    "        self.alpha = alpha\n",
    "\n",
    "        \n",
    "    def betaUpdate(self):\n",
    "        \"\"\"Update du vecteur beta specificity (1xR)\"\"\"\n",
    "        \n",
    "        beta = []\n",
    "        for j in range(0,self.R):\n",
    "            tmp1 = 0\n",
    "            tmp2 = 0\n",
    "            for i in range(0,self.N):\n",
    "                if (np.isnan(self.y[i][j])==False):\n",
    "                    tmp1 += (1-self.mu[i])*(1-self.y[i][j])\n",
    "                    tmp2 += 1-self.mu[i]\n",
    "            beta.append((self.b_prior[0][j]-1+tmp1)/(self.b_prior[0][j]+self.b_prior[1][j]-2+tmp2))\n",
    "        self.beta = beta\n",
    "\n",
    "        \n",
    "    def wUpdate(self):\n",
    "        \"\"\"Update du vecteur poids w (1xR)\"\"\"\n",
    "        \n",
    "        g = 0\n",
    "        for i in range(0,self.N):\n",
    "            g += (self.mu[i] - sigma(self.x[i].dot(self.w.T)))*self.x[i]\n",
    "        tmp = np.reshape(-self.gamma_prior.dot(self.w.T),g.shape) # (11,1) -> (11,)\n",
    "        g += tmp\n",
    "    \n",
    "        H = np.zeros((self.D,self.D))\n",
    "        for i in range(0,self.N):\n",
    "            H -= sigma(self.x[i].dot(self.w.T))*(1-sigma(self.x[i].dot(self.w.T)))*((self.x[i].reshape(self.D,1))*(self.x[i].reshape(1,self.D)))\n",
    "        H -= self.gamma_prior\n",
    "        self.w = self.w - self.eta*np.linalg.inv(H).dot(g)\n",
    "    \n",
    "    \n",
    "    def score(self, seuil = 1/2):\n",
    "        \"\"\"Quel est le score d'apprentissage de notre modèle ?\"\"\"\n",
    "        return np.mean(np.equal(self.trueLabel, np.array(self.mu)>seuil))\n",
    "    \n",
    "    \n",
    "    def scoreMoy(self, seuil = 1/2):\n",
    "        \"\"\"Quel serait le score si on fesait naïvement la moyenne des avis des annotateurs ?\"\"\"\n",
    "        return np.mean(np.equal(self.trueLabel, np.nanmean(self.y, axis = 1)>seuil))\n",
    "\n",
    "    \n",
    "    def train(self, mean_prior1, var_prior1, mean_prior2, var_prior2, gamma_prior, maxIter = 1000, eta = 0.01, epsilon = 1e-10, graphe=True):\n",
    "        \"\"\"Fonction qui lance l'entrainement du modèle.\n",
    "        La variable graphe sert à plotter la log-likelihood au fil des itérations.\n",
    "        La log-likelihood devrait être croissante.\"\"\"\n",
    "        \n",
    "        self.maxIter = maxIter\n",
    "        self.eta = eta\n",
    "        \n",
    "        self.initPrior(mean_prior1, var_prior1, mean_prior2, var_prior2, gamma_prior)\n",
    "        self.initMu()\n",
    "        self.alphaUpdate()\n",
    "        self.betaUpdate()\n",
    "        self.w = np.random.rand(1,self.D)\n",
    "\n",
    "        compteur = 0\n",
    "        self.histLogLikelihood = []\n",
    "        \n",
    "        while (compteur < maxIter):\n",
    "            self.mui()\n",
    "            self.alphaUpdate()\n",
    "            self.betaUpdate()\n",
    "            wOld = self.w\n",
    "            self.wUpdate()\n",
    "            wNew = self.w\n",
    "            \n",
    "            self.histLogLikelihood.append(self.logLikelihood())\n",
    "            diffW = wOld - wNew\n",
    "            if (np.linalg.norm(diffW) < self.N*epsilon):\n",
    "                print(\"SEUIL DE CONVERGENCE SUR W ATTEINT\")\n",
    "                print (\"ITERATION : \", compteur)\n",
    "                print(\"Vraissemblance : \", self.logLikelihood())\n",
    "                print(\"Norme de diff_w : \", np.linalg.norm(diffW))\n",
    "                print(\"Alpha : \", self.alpha)\n",
    "                print(\"Beta : \", self.beta)\n",
    "                break\n",
    "            \n",
    "            if (compteur % 100 == 0):\n",
    "                print (\"ITERATION : \", compteur)\n",
    "                print(\"Vraissemblance : \", self.logLikelihood())\n",
    "                print(\"Norme de diff_w : \", np.linalg.norm(diffW))\n",
    "                print(\"Alpha : \", self.alpha)\n",
    "                print(\"Beta : \", self.beta)\n",
    "            compteur = compteur + 1\n",
    "        \n",
    "        if graphe:\n",
    "            plt.plot(self.histLogLikelihood)\n",
    "            plt.title('Log-vraissemblance au fil des itérations')\n",
    "\n",
    "    def roc(self) :\n",
    "        falsePR, truePR, threshold = roc_curve(self.trueLabel, self.mu) #falsePositiveRate and truePositiveRate\n",
    "        falsePR1, truePR1, threshold1 = roc_curve(self.trueLabel, np.nanmean(self.y, axis = 1))\n",
    "        roc_auc = auc(falsePR, truePR)\n",
    "        roc_auc1 = auc(falsePR1, truePR1)\n",
    "        plt.plot(falsePR, truePR, lw=2, label='ROC - AUC = %0.2f)'%(roc_auc))\n",
    "        plt.plot(falsePR1, truePR1, lw = 2, label = 'ROC - AUC = %0.2f)'%(roc_auc1))\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Paramètres du data set\n",
    "D = 10\n",
    "R = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Nos hypothèses\n",
    "#Sensitivity\n",
    "mean_prior1 = np.array([0.9, 0.8, 0.4, 0.2, 0.1]) #Quel pourcentage de bonnes réponses l'expert donne en moyenne ?\n",
    "var_prior1 = np.array([1,1,1,1,1]) #Avec quelle incertitude ?\n",
    "\n",
    "#Sensibility\n",
    "mean_prior2 = np.array([0.85, 0.75, 0.45, 0.25, 0.1]) #Quel pourcentage de bonnes réponses l'expert donne en moyenne ?\n",
    "var_prior2 = np.array([1,1,1,1,1]) #Avec quelle incertitude ?\n",
    "\n",
    "#Weights\n",
    "gamma_prior = np.identity(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-19613157774a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbreast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbreast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchargeData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Datasets/BreastCancer/DB_wdbcSparse.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbreast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_prior1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_prior1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_prior2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_prior2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma_prior\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxIter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraphe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "breast = modelSparse(D, R)\n",
    "breast.chargeData('Datasets/DebugBis.csv')\n",
    "breast.train(mean_prior1, var_prior1, mean_prior2, var_prior2, gamma_prior,maxIter = 500, eta = 1, graphe = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION :  0\n",
      "Vraissemblance :  [-1544.83233207]\n",
      "Norme de diff_w :  0.673833381118\n",
      "Alpha :  [array([ 0.76799883]), array([ 0.78556805]), array([ 0.60414457]), array([ 0.5875114]), array([ 0.53383604])]\n",
      "Beta :  [array([ 0.92649175]), array([ 0.83988907]), array([ 0.63073755]), array([ 0.62941373]), array([ 0.59429554])]\n",
      "SEUIL DE CONVERGENCE SUR W ATTEINT\n",
      "ITERATION :  25\n",
      "Vraissemblance :  [-1485.73408828]\n",
      "Norme de diff_w :  4.33244523601e-08\n",
      "Alpha :  [array([ 0.91379648]), array([ 0.86713804]), array([ 0.61948226]), array([ 0.57927899]), array([ 0.51984699])]\n",
      "Beta :  [array([ 0.96431574]), array([ 0.8540506]), array([ 0.62494893]), array([ 0.61114518]), array([ 0.57752557])]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEKCAYAAADn+anLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2TZpSXsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c977d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "breast = modelSparse(D, R)\n",
    "breast.chargeData('Datasets/BreastCancer/DB_wdbcSparse.csv')\n",
    "breast.train(mean_prior1, var_prior1, mean_prior2, var_prior2, gamma_prior,maxIter = 500, eta = 1, graphe = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LE SCORE D'ENTRAINEMENT EST DE :  0.499702558001\n",
      "LE SCORE NAIF DE MOYENNE DES ANNOTATEURS EST DE :  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"LE SCORE D'ENTRAINEMENT EST DE : \", breast.score())\n",
    "print(\"LE SCORE NAIF DE MOYENNE DES ANNOTATEURS EST DE : \", breast.scoreMoy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEACAYAAABWLgY0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFh5JREFUeJzt3X9sVfX9x/HXuyBO6A8KRCloiwrEwIT9UL4a1FyQDNhI\nQOdU6pxiluiUZRMWEZ3CskV0mZtRoxubmUNlfuc0ij+IMGa3YXGwpMJ3pR0Cyi8bsBRoGcJqeX//\n6KW9Lbftae/tbfvZ85Hc5J5zP+fcdz85ffX0c+49H3N3AQDClNXTBQAAug8hDwABI+QBIGCEPAAE\njJAHgIAR8gAQsA5D3syeMbP9ZralnTaPm9kHZva+mX0hvSUCALoqypn8byVNb+tFM5sp6UJ3HyPp\ndkm/TFNtAIAUdRjy7r5e0qF2msyWtCLe9u+S8szsnPSUBwBIRTrG5EdK2pOwvC++DgDQw7jwCgAB\n65+GfeyTdF7C8rnxdacxM26UAwBd4O7Wle2inslb/JHMKknfkiQzu0zSYXff39aO3J2Hu5YsWdLj\nNfSWB31BX9AXbT+k1M6NOzyTN7OVkmKShprZbklLJA1ozGtf7u5vmdlXzWy7pH9LmpdSRQCAtOkw\n5N29OEKb+ekpBwCQTlx47SGxWKynS+g16Itm9EUz+iI9rHHMJ0NvZuaZfD8A6OvMJMnkXbzwmo5P\n1wDBGjVqlHbt2tXTZeC/RFFRkT766KO07pMzeaAdZiaOWWRKsuMt1TN5xuQBIGCEPAAEjJAHgIAR\n8gCQAQcOHNC4ceNUX1+f0fcl5IE+bNSoURo4cKByc3M1YsQIzZs3T8eOHWvRprS0VFdffbVyc3OV\nn5+v2bNnq6KiokWburo6ff/731dRUZFyc3M1ZswYLViwQDU1NSnVd+utt+qMM87Q/v0t73Qyb948\nPfjggy3W7dq1S1lZWTp58mTTupUrV+rSSy9VTk6ORo4cqa997Wt69913U6qptf/85z+67bbblJeX\npxEjRugXv/hFu+1XrlypUaNGKScnR9dee60OHz4caV9nn322pk6dql/96ldprb8jhDzQh5mZ3nzz\nTdXW1ur9999XWVmZli1b1vT6hg0bNH36dF1zzTWqqqrShx9+qAkTJmjy5MlNH9Wrr6/X1KlTVVFR\noTVr1qi2tlYbNmzQsGHDtHHjxi7XduzYMb3yyisaPHiwnn/++cg/zyk///nPtWDBAv3whz/UgQMH\ntHv3bt111116/fXXu1xTMkuWLNGOHTu0Z88e/fnPf9ZPf/pTrVmzJmnb8vJy3XHHHXrhhRe0f/9+\nnXXWWfrOd74TeV/FxcUZD/kM32hHDvQlvf2YHTVqlK9bt65p+Z577vFZs2Y1LV955ZU+f/7807ab\nOXOm33LLLe7u/utf/9qHDx/ux44dS2ttv/vd77ywsNAff/xx//znP9/itVtvvdUfeOCBFus++ugj\nz8rK8oaGBj9y5IhnZ2f7yy+/nNaakhkxYoT/6U9/alp+8MEHfe7cuUnb3nfffX7TTTc1Le/YscMH\nDBjgR48ejbSvzz77zAcOHOi7d+9Ouv9kx5vUtL5LucuZPJACs/Q9UrV3716tXr1aY8aMkSR9+umn\nKi0t1XXXXXda2+uvv15r166VJK1bt04zZszQWWedlXoRCVasWKHi4mLdcMMNqqysVFlZWeRtS0tL\ndeLECc2ZMyfyNo888ojy8/M1ZMgQ5efnt3g+ZMiQpNscPnxYVVVVmjBhQtO6iRMnqry8PGn78vJy\nTZw4sWn5ggsu0Jlnnqlt27ZF2le/fv00evRobd68OfLPlSpCHujj5syZo9zcXBUWFuqcc87R0qVL\nJUk1NTU6efKkCgoKTtumoKBA1dXVkqSDBw8mbZOK3bt365133lFxcbHOPvtsTZs2TStWrIi8fU1N\njYYNG6asrOgRtWjRIh06dEg1NTU6dOhQi+dtXVs4evSozEx5eXlN63Jzc1VXV9dm+8S2ie2j7isn\nJ6fFOH53I+SBFJz6Zzodj6567bXXVFtbq7/85S+qrKxsCu/8/HxlZWWpqqrqtG2qqqo0bNgwSdLQ\noUOTtmnLsmXLlJOTo9zcXN15551J2zz33HMaN26cLr74YknS3Llz9cILL6ihoUGS1L9//9M+ZVJf\nX6+srCxlZWVp6NChqq6ubnERtjtkZ2dLkmpra5vWHTlyRDk5OW22T2yb2D7qvurq6jR48OC01B8F\nIQ/0cR7/C3HllVfqlltu0cKFCyVJAwcO1OWXX66XXnrptG3+8Ic/aNq0aZKkadOm6e2339ann34a\n6f0WL16suro61dbW6qmnnkra5rnnntPOnTtVUFCggoICLVy4UAcPHtRbb70lSSosLDztHi07d+7U\neec1TjJ3+eWX68wzz9Srr74aqSap5R+fxMepdckMHjxYBQUFLYZPNm/erPHjxydtP378+BZtd+zY\nofr6eo0dOzbSvhoaGrR9+/YWQz7drquD+V15qJdfxAJa6+3HbOsLr5988okPGjTIt2zZ4u7u69ev\n9+zsbH/iiSe8rq7Oa2pq/P777/f8/Hzfvn27u7ufOHHCJ02a5DNnzvTKyko/efKkV1dX+0MPPeSr\nV6/udE2lpaV+xhlneHl5ue/fv7/pcdNNN/nXv/51d3cvLy/3nJwcX7t2rTc0NPi+ffv8qquu8vvu\nu69pP48++qgPHz7cX331VT927JjX19f76tWrfdGiRal02Wnuvfdej8VifujQId+6dasPHz7c16xZ\nk7RteXm55+Xl+fr16/3o0aNeXFzsxcXFkfdVWlrq48ePb7OWZMdbqhdeCXmgHb39mD3//PNbhLy7\n+5133unXXXdd0/K7777rsVjMs7OzPS8vz2fNmuVbt25tsU1tba3ffffdft5553lOTo6PHj3aFy5c\n6DU1NZ2u6Y477vBvfOMbp63fuHGjf+5zn/NDhw65u/sbb7zhX/7yl33w4ME+atQoX7RokR8/frzF\nNitXrvRLLrnEs7OzvaCgwGfNmuUbNmzodE3tOXHihN92222em5vrw4cP98cee6zF69nZ2b5+/fqm\n5d///vdeWFjo2dnZfs011zT9PFH2ddddd/kTTzzRZi3dEfLchRJoB3ehRLp88sknisViKisr04AB\nA5K26Y67UBLyQDsIeWQStxoGAHQKIQ8AASPkASBghDwABIyQB4CAEfIAEDBCHgACRsgDQAYw/R+A\nTmP6v9S99NJLmjx5sgYNGqSpU6d22J7p/wBkDNP/pW7o0KG6++67tXjx4g7bMv0fNyhDYHr7Mcv0\nf+nzm9/8xqdMmdJum744/V//zP5JAcJiP0rDvH1xviS1e+Scmv7v1H3iT03/9+Mf//i0ttdff73u\nv/9+SZmZ/m/BggUqKyvTF7/4xUjbdnX6v4cffrjF/V9OPTezlIeepMYz+cmTJzctJ07/d/755yed\n/i/xnviJ0/+dund+d2O4BujjmP6vUVem/+usvjj9H2fyQApSPftOh9dee01TpkzR3/72NxUXF6u6\nurrpIuup6f/Gjh3bYptUp/976KGHZGb65je/mXR2qGTT//3gBz/Qz372M/Xr169T0/91Jui7W9Tp\n/071LdP/AUjZqaEJpv/r/PR/ncX0f1x4RWB6+zHL9H+pa2ho8OPHj/vTTz/tV111lR8/ftzr6+uT\ntmX6P0IegentxyzT/6Xu2WefdTPzrKyspse8efOaXv+vmP7PzGZIekyNwzvPuPsjrV7PlfS8pEJJ\n/SQ96u7PJtmPR3k/oLdgZiikS6+d/s/MsiRtk3S1pI8lbZJ0o7tXJrRZLCnX3Reb2TBJ/5J0jrt/\n1mpfhDz6FEIemdRT0/9NkvSBu+9y93pJL0qa3aqNSzp1CTlH0sHWAQ8AyLwoIT9S0p6E5b3xdYme\nlDTOzD6WtFnS99JTHgAgFen6nPx0SWXuPtXMLpS01swmuPvR1g1PfVFDkmKxmGKxWJpKAIAwlJSU\nqKSkJC37ijImf5mkpe4+I758rxqv9D6S0OYNScvc/d348jpJi9z9H632xZg8+hTG5JFJPTUmv0nS\naDMrMrMBkm6UtKpVm12SpsWLPEfSWEk7u1IQACB9OhyucfcGM5svaY2aP0JZYWa3N77syyX9RNKz\nZrYlvtk97p6em0UAPaioqKjF7W+B7lRUVJT2fUb6nHza3ozhGgDolEwM1wAA+ihCHgACRsgDQMAI\neQAIGCEPAAEj5AEgYIQ8AASMkAeAgBHyABAwQh4AAkbIA0DACHkACBghDwABI+QBIGCEPAAEjJAH\ngIAR8gAQMEIeAAJGyANAwAh5AAgYIQ8AASPkASBghDwABIyQB4CAEfIAEDBCHgACRsgDQMAIeQAI\nGCEPAAEj5AEgYIQ8AASMkAeAgBHyABAwQh4AAkbIA0DAIoW8mc0ws0oz22Zmi9poEzOzMjP7p5m9\nk94yAQBdYe7efgOzLEnbJF0t6WNJmyTd6O6VCW3yJJVK+oq77zOzYe5enWRf3tH7AQCamUmSyd2t\nK9tHOZOfJOkDd9/l7vWSXpQ0u1WbYkkvu/s+SUoW8ACAzIsS8iMl7UlY3htfl2ispCFm9o6ZbTKz\nm9NVIACg6/qncT9fkjRV0iBJG8xsg7tvT9P+AQBdECXk90kqTFg+N74u0V5J1e5+XNJxM/urpImS\nTgv5pUuXNj2PxWKKxWKdqxgAAldSUqKSkpK07CvKhdd+kv6lxguvVZI2Sprr7hUJbS6S9ISkGZLO\nlPR3STe4+9ZW++LCKwB0QqoXXjs8k3f3BjObL2mNGsfwn3H3CjO7vfFlX+7ulWb2tqQtkhokLW8d\n8ACAzOvwTD6tb8aZPAB0SiY+QgkA6KMIeQAIGCEPAAEj5AEgYIQ8AASMkAeAgBHyABAwQh4AAkbI\nA0DACHkACBghDwABI+QBIGCEPAAEjJAHgIAR8gAQMEIeAAJGyANAwAh5AAgYIQ8AASPkASBghDwA\nBIyQB4CAEfIAEDBCHgACRsgDQMAIeQAIGCEPAAEj5AEgYIQ8AASMkAeAgBHyABAwQh4AAkbIA0DA\nCHkACBghDwABI+QBIGCRQt7MZphZpZltM7NF7bS71Mzqzeza9JUIAOiqDkPezLIkPSlpuqTxkuaa\n2UVttHtY0tvpLhIA0DVRzuQnSfrA3Xe5e72kFyXNTtLuu5L+KOlAGusDAKQgSsiPlLQnYXlvfF0T\nMxshaY67Py3J0lceACAV6brw+pikxLF6gh4AeoH+Edrsk1SYsHxufF2iSyS9aGYmaZikmWZW7+6r\nWu9s6dKlTc9jsZhisVgnSwaAsJWUlKikpCQt+zJ3b7+BWT9J/5J0taQqSRslzXX3ijba/1bS6+7+\nSpLXvKP3AwA0M5Mkk7t3aYSkwzN5d28ws/mS1qhxeOcZd68ws9sbX/blrTfpSiEAgPTr8Ew+rW/G\nmTwAdEqqZ/J84xUAAkbIA0DACHkACBghDwABI+QBIGCEPAAEjJAHgIAR8gAQMEIeAAJGyANAwAh5\nAAgYIQ8AASPkASBghDwABIyQB4CAEfIAEDBCHgACRsgDQMAIeQAIGCEPAAEj5AEgYIQ8AASMkAeA\ngBHyABAwQh4AAkbIA0DACHkACBghDwABI+QBIGCEPAAEjJAHgIAR8gAQMEIeAAJGyANAwAh5AAgY\nIQ8AAYsU8mY2w8wqzWybmS1K8nqxmW2OP9ab2cXpLxUA0Fnm7u03MMuStE3S1ZI+lrRJ0o3uXpnQ\n5jJJFe5+xMxmSFrq7pcl2Zd39H4AgGZmkmRyd+vK9lHO5CdJ+sDdd7l7vaQXJc1ObODu77n7kfji\ne5JGdqUYAEB6RQn5kZL2JCzvVfsh/m1Jq1MpCgCQHv3TuTMzmyJpnqQr2mqzdOnSpuexWEyxWCyd\nJQBAn1dSUqKSkpK07CvKmPxlahxjnxFfvleSu/sjrdpNkPSypBnuvqONfTEmDwCdkIkx+U2SRptZ\nkZkNkHSjpFUti7BCNQb8zW0FPAAg8zocrnH3BjObL2mNGv8oPOPuFWZ2e+PLvlzSA5KGSHrKzExS\nvbtP6s7CAQAd63C4Jq1vxnANAHRKJoZrAAB9FCEPAAEj5AEgYIQ8AASMkAeAgBHyABAwQh4AAkbI\nA0DACHkACBghDwABI+QBIGCEPAAEjJAHgIAR8gAQMEIeAAJGyANAwAh5AAgYIQ8AASPkASBghDwA\nBIyQB4CAEfIAEDBCHgACRsgDQMAIeQAIGCEPAAEj5AEgYIQ8AASMkAeAgBHyABAwQh4AAkbIA0DA\nCHkACBghDwABI+QBIGCRQt7MZphZpZltM7NFbbR53Mw+MLP3zewL6S0TANAVHYa8mWVJelLSdEnj\nJc01s4tatZkp6UJ3HyPpdkm/7IZag1JSUtLTJfQa9EUz+qIZfZEeUc7kJ0n6wN13uXu9pBclzW7V\nZrakFZLk7n+XlGdm56S10sBwADejL5rRF83oi/SIEvIjJe1JWN4bX9dem31J2gAAMqx/pt/QLNPv\n2Hv96Ec9XUHvQV80oy+a0RepixLy+yQVJiyfG1/Xus15HbSJI+WbcQQ3oy+a0RfN6ItURQn5TZJG\nm1mRpCpJN0qa26rNKkl3SfpfM7tM0mF33996R+5OwgNABnUY8u7eYGbzJa1R4xj+M+5eYWa3N77s\ny939LTP7qpltl/RvSfO6t2wAQBTm7j1dAwCgm3TLN1758lSzjvrCzIrNbHP8sd7MLu6JOjMhynER\nb3epmdWb2bWZrC+TIv6OxMyszMz+aWbvZLrGTInwO5JrZqviWfF/ZnZrD5TZ7czsGTPbb2Zb2mnT\n+dx097Q+1PiHY7ukIklnSHpf0kWt2syU9Gb8+f9Iei/ddfSGR8S+uExSXvz5jP/mvkhot07SG5Ku\n7em6e/C4yJNULmlkfHlYT9fdg32xWNKyU/0g6aCk/j1dezf0xRWSviBpSxuvdyk3u+NMni9PNeuw\nL9z9PXc/El98T+F+vyDKcSFJ35X0R0kHMllchkXpi2JJL7v7Pkly9+oM15gpUfrCJeXEn+dIOuju\nn2Wwxoxw9/WSDrXTpEu52R0hz5enmkXpi0TflrS6WyvqOR32hZmNkDTH3Z9W2J+1jXJcjJU0xMze\nMbNNZnZzxqrLrCh98aSkcWb2saTNkr6Xodp6my7lZsa/DIXkzGyKGj+VdEVP19KDHpOUOCYbctB3\npL+kL0maKmmQpA1mtsHdt/dsWT1iuqQyd59qZhdKWmtmE9z9aE8X1hd0R8in+ctTfVqUvpCZTZC0\nXNIMd2/v37W+LEpfXCLpRTMzNY69zjSzendflaEaMyVKX+yVVO3uxyUdN7O/SpqoxvHrkETpi3mS\nlkmSu+8wsw8lXSTpHxmpsPfoUm52x3BN05enzGyAGr881fqXdJWkb0lSe1+eCkCHfWFmhZJelnSz\nu+/ogRozpcO+cPcL4o/z1Tguf2eAAS9F+x15TdIVZtbPzAaq8UJbRYbrzIQofbFL0jRJio9Bj5W0\nM6NVZo6p7f9gu5SbaT+Td7481SRKX0h6QNIQSU/Fz2Dr3X1Sz1XdPSL2RYtNMl5khkT8Hak0s7cl\nbZHUIGm5u2/twbK7RcTj4ieSnk34aOE97l7TQyV3GzNbKSkmaaiZ7Za0RNIApZibfBkKAALG9H8A\nEDBCHgACRsgDQMAIeQAIGCEPAAEj5AEgYIQ8AASMkAeAgP0/hxqkZDYHvqEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2652f4625c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "breast.roc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LE RESTE EST UN BROUILLON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wine = pd.read_csv('Datasets/whiteWine.csv', delimiter = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = 11  #descripteurs\n",
    "N =  wine.shape[0] #produits à tester\n",
    "R = 5 #experts\n",
    "\n",
    "y = np.array(wine.ix[:,d+2:]) #labels des annotateurs\n",
    "x = np.array(wine.ix[:,0:d]) #variables explicatives\n",
    "w0 = np.random.rand(1,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def init_mu(y):\n",
    "\tmu = []\n",
    "\tfor i in range(0,N):\n",
    "\t\tmu.append(np.sum(y[i])/R)\n",
    "\treturn mu\n",
    "\n",
    "mu0 = init_mu(y)\n",
    "\n",
    "def sigma(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def logit(z):\n",
    "    return np.log(z/(1-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Nos hypothèses\n",
    "#Sensitivity\n",
    "mean_prior1 = np.random.rand(R) #Quel pourcentage de bonnes réponses l'expert donne en moyenne ?\n",
    "var_prior1 = np.random.rand(R) #Avec quelle incertitude ?\n",
    "#Sensibility\n",
    "mean_prior2 = np.random.rand(R) #Quel pourcentage de bonnes réponses l'expert donne en moyenne ?\n",
    "var_prior2 = np.random.rand(R) #Avec quelle incertitude ?\n",
    "#Weights\n",
    "gamma_prior = np.random.rand(d,d)\n",
    "\n",
    "#On en déduit les paramètres \n",
    "a_prior = np.random.rand(2,R) \n",
    "b_prior = np.random.rand(2,R)\n",
    "for i in range(0,R):\n",
    "    a_prior[0][i] = (-mean_prior1[i]**3 + mean_prior1[i]**2 -mean_prior1[i]*var_prior1[i]**2)/var_prior1[i]**2\n",
    "    a_prior[1][i] = a_prior[0][i]*(1-mean_prior1[i])/mean_prior1[i]\n",
    "    b_prior[0][i] = (-mean_prior2[i]**3 + mean_prior2[i]**2 -mean_prior2[i]*var_prior2[i]**2)/var_prior2[i]**2\n",
    "    b_prior[1][i] = b_prior[0][i]*(1-mean_prior2[i])/mean_prior2[i]\n",
    "\n",
    "\n",
    "gamma_prior = np.linalg.inv(gamma_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#E-step\n",
    "\n",
    "def ai(alpha,y):\n",
    "    a = []\n",
    "    for i in range(0,N):\n",
    "        proda = 1\n",
    "        for j in range(0,R):\n",
    "            proda = proda*alpha[j]**(y[i][j])*(1-alpha[j])**(1-y[i][j])\n",
    "        a.append(proda)\n",
    "    return a\n",
    "\n",
    "def bi(beta,y):\n",
    "    b = []\n",
    "    for i in range(0,N):\n",
    "        prodb = 1\n",
    "        for j in range(0,R):\n",
    "            prodb = prodb*beta[j]**(1-y[i][j])*(1-beta[j])**(y[i][j])\n",
    "        b.append(prodb)\n",
    "    return b\n",
    "\n",
    "def pi(x,w):\n",
    "    p = []\n",
    "    for i in range(0,N):\n",
    "        p.append(sigma(x[i].dot(w.T)))\n",
    "    return p\n",
    "\n",
    "def mui(a,b,p):\n",
    "    mu = []\n",
    "    for i in range(0,N):\n",
    "        mu.append(a[i]*p[i]/(a[i]*p[i]+b[i]*(1-p[i])))\n",
    "    return mu\n",
    "\n",
    "def E_step(x,y,alpha,beta,w):\n",
    "    a = ai(alpha,y)\n",
    "    b = bi(beta,y)\n",
    "    p = pi(x,w)\n",
    "    mu = mui(a,b,p)\n",
    "    return mu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Log - Likelihood Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logLikelihood(w, y, alpha, beta):\n",
    "    a = ai(alpha, y)\n",
    "    b = bi(beta, y)\n",
    "    p = pi(x, w)\n",
    "    \n",
    "    #On calcule directement la log-vraissemblance.\n",
    "    vraissemblance = 0\n",
    "    for i in range(0,N):\n",
    "        vraissemblance = vraissemblance + np.log((a[i]*p[i])+b[i]*(1-p[i]))\n",
    "        \n",
    "    return vraissemblance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#M-step\n",
    "\n",
    "def alpha_function(mu,y,a_prior):\n",
    "\talpha = []\n",
    "\tfor j in range(0,R):\n",
    "\t\ttmp1 = 0\n",
    "\t\ttmp2 = 0\n",
    "\t\tfor i in range(0,N):\n",
    "\t\t\ttmp1 += mu[i]*y[i][j]\n",
    "\t\t\ttmp2 += mu[i]\n",
    "\t\talpha.append((a_prior[0][j]-1+tmp1)/(a_prior[0][j]+a_prior[1][j]-2+tmp2))\n",
    "\treturn alpha\n",
    "\n",
    "def beta_function(mu,y,b_prior):\n",
    "\tbeta = []\n",
    "\tfor j in range(0,R):\n",
    "\t\ttmp1 = 0\n",
    "\t\ttmp2 = 0\n",
    "\t\tfor i in range(0,N):\n",
    "\t\t\ttmp1 += (1-mu[i])*(1-y[i][j])\n",
    "\t\t\ttmp2 += 1-mu[i]\n",
    "\t\tbeta.append((b_prior[0][j]-1+tmp1)/(b_prior[0][j]+b_prior[1][j]-2+tmp2))\n",
    "\treturn beta\n",
    "\n",
    "def updateW(w,x, eta, mu, gamma_prior):\n",
    "    g = 0\n",
    "    for i in range(0,N):\n",
    "        g += (mu[i] - sigma(x[i].dot(w.T)))*x[i]\n",
    "    tmp = np.reshape(-gamma_prior.dot(w.T),g.shape) # (11,1) -> (11,)\n",
    "    g += tmp\n",
    "    \n",
    "    H = np.zeros((d,d))\n",
    "    for i in range(0,N):\n",
    "        H -= sigma(x[i].dot(w.T))*(1-sigma(x[i].dot(w.T)))*((x[i].reshape(11,1))*(x[i].reshape(1,11)))\n",
    "    H -= gamma_prior\n",
    "    w = w - eta*np.linalg.inv(H).dot(g)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-35334.92901159, -28871.41002449, -37022.64471383, -24159.64331136,\n",
       "        -33242.01854823, -20056.53651041, -34332.7256707 ,  -6830.87748493,\n",
       "        -27080.53161824, -13806.67227696, -20106.51189462]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updateW(w0,x,0.1,mu0,gamma_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Itérations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION :  0\n",
      "Vraissemblance :  [-12941.84181545]\n",
      "Norme de diff_w :  0.0189439655636\n",
      "Alpha :  [array([ 0.89419982]), array([ 0.70627847]), array([ 0.51154001]), array([ 0.40361302]), array([ 0.1026994])]\n",
      "Beta :  [array([ 0.4933009]), array([ 0.39185742]), array([ 0.55288447]), array([ 0.55593145]), array([ 0.84461565])]\n",
      "ITERATION :  10\n",
      "Vraissemblance :  [-12941.84181559]\n",
      "Norme de diff_w :  0.0171301718401\n",
      "Alpha :  [array([ 0.89419982]), array([ 0.70627847]), array([ 0.51154001]), array([ 0.40361302]), array([ 0.1026994])]\n",
      "Beta :  [array([ 0.49330092]), array([ 0.39185747]), array([ 0.55288447]), array([ 0.55593144]), array([ 0.84461576])]\n",
      "ITERATION :  20\n",
      "Vraissemblance :  [-12941.84181615]\n",
      "Norme de diff_w :  0.0154828695169\n",
      "Alpha :  [array([ 0.89419982]), array([ 0.70627847]), array([ 0.51154001]), array([ 0.40361302]), array([ 0.1026994])]\n",
      "Beta :  [array([ 0.49330103]), array([ 0.39185767]), array([ 0.55288445]), array([ 0.55593141]), array([ 0.84461627])]\n",
      "ITERATION :  30\n",
      "Vraissemblance :  [-12941.84181812]\n",
      "Norme de diff_w :  0.0139711304341\n",
      "Alpha :  [array([ 0.89419982]), array([ 0.70627847]), array([ 0.51154001]), array([ 0.40361302]), array([ 0.1026994])]\n",
      "Beta :  [array([ 0.49330142]), array([ 0.39185836]), array([ 0.55288442]), array([ 0.55593129]), array([ 0.84461821])]\n",
      "ITERATION :  40\n",
      "Vraissemblance :  [-12941.84182403]\n",
      "Norme de diff_w :  0.0125448593163\n",
      "Alpha :  [array([ 0.89419982]), array([ 0.70627847]), array([ 0.51154001]), array([ 0.40361302]), array([ 0.1026994])]\n",
      "Beta :  [array([ 0.49330257]), array([ 0.3918603]), array([ 0.55288443]), array([ 0.55593088]), array([ 0.84462474])]\n",
      "ITERATION :  50\n",
      "Vraissemblance :  [-12941.84183913]\n",
      "Norme de diff_w :  0.0111257616387\n",
      "Alpha :  [array([ 0.89419983]), array([ 0.70627847]), array([ 0.51154001]), array([ 0.40361301]), array([ 0.1026994])]\n",
      "Beta :  [array([ 0.49330552]), array([ 0.39186481]), array([ 0.5528848]), array([ 0.5559297]), array([ 0.84464394])]\n",
      "ITERATION :  60\n",
      "Vraissemblance :  [-12941.84187111]\n",
      "Norme de diff_w :  0.00964115269927\n",
      "Alpha :  [array([ 0.89419983]), array([ 0.70627847]), array([ 0.51154001]), array([ 0.40361301]), array([ 0.1026994])]\n",
      "Beta :  [array([ 0.49331172]), array([ 0.39187297]), array([ 0.55288661]), array([ 0.55592675]), array([ 0.84469191])]\n",
      "ITERATION :  70\n",
      "Vraissemblance :  [-12941.84192556]\n",
      "Norme de diff_w :  0.00813492985545\n",
      "Alpha :  [array([ 0.89419983]), array([ 0.70627847]), array([ 0.51154001]), array([ 0.40361299]), array([ 0.1026994])]\n",
      "Beta :  [array([ 0.49332217]), array([ 0.39188359]), array([ 0.55289192]), array([ 0.55592076]), array([ 0.84478952])]\n",
      "ITERATION :  80\n",
      "Vraissemblance :  [-12941.84200015]\n",
      "Norme de diff_w :  0.00678528456894\n",
      "Alpha :  [array([ 0.89419984]), array([ 0.70627847]), array([ 0.51154001]), array([ 0.40361297]), array([ 0.10269941])]\n",
      "Beta :  [array([ 0.49333627]), array([ 0.39189246]), array([ 0.55290288]), array([ 0.55591103]), array([ 0.84494825])]\n",
      "ITERATION :  90\n",
      "Vraissemblance :  [-12941.84208632]\n",
      "Norme de diff_w :  0.00571025943566\n",
      "Alpha :  [array([ 0.89419985]), array([ 0.70627848]), array([ 0.51154]), array([ 0.40361294]), array([ 0.10269941])]\n",
      "Beta :  [array([ 0.49335217]), array([ 0.39189524]), array([ 0.55292015]), array([ 0.55589791]), array([ 0.84516111])]\n"
     ]
    }
   ],
   "source": [
    "mu = init_mu(y)\n",
    "alpha = alpha_function(mu,y,a_prior)\n",
    "beta = beta_function(mu,y,b_prior)\n",
    "diff_w = 10\n",
    "w = w0\n",
    "\n",
    "compteur = 0\n",
    "\n",
    "#while (np.linalg.norm(diff_w) > 0.001) : # Limite de convergence à decider\n",
    "while (compteur < 100):\n",
    "    mu = E_step(x,y,alpha,beta,w)\n",
    "    alpha = alpha_function(mu,y,a_prior)\n",
    "    beta = beta_function(mu,y,b_prior)\n",
    "    w_bis = updateW(w,x,0.01,mu,gamma_prior)\n",
    "    diff_w = w - w_bis\n",
    "    w = w_bis\n",
    "    if (compteur % 10 == 0):\n",
    "        print (\"ITERATION : \", compteur)\n",
    "        print(\"Vraissemblance : \", logLikelihood(w, y, alpha, beta))\n",
    "        print(\"Norme de diff_w : \", np.linalg.norm(diff_w))\n",
    "        print(\"Alpha : \", alpha)\n",
    "        print(\"Beta : \", beta)\n",
    "    compteur = compteur + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.85478903e+00]\n",
      " [  2.78241174e-01]\n",
      " [  3.34191573e-01]\n",
      " [  6.39141613e+00]\n",
      " [  4.57723652e-02]\n",
      " [  3.53080920e+01]\n",
      " [  1.38360685e+02]\n",
      " [  9.94027574e-01]\n",
      " [  3.18826727e+00]\n",
      " [  4.89846974e-01]\n",
      " [  1.05142691e+01]] [[  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  1.85919375e-09]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [ -2.10763051e-07]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [ -3.53501284e-03]]\n"
     ]
    }
   ],
   "source": [
    "#weight of each expert\n",
    "weights = logit(np.array(alpha))+logit(np.array(beta))\n",
    "\n",
    "#Sensitivity and sensibility of classifiers\n",
    "alpha_clas = []\n",
    "beta_clas = []\n",
    "for j in range(0,d):\n",
    "    tmp = 0\n",
    "    tmp2 = 0\n",
    "    for i in range(0,N):\n",
    "        tmp += mu[j]*x[i][j]\n",
    "        tmp2 += (1-mu[j])*(1-x[i][j])\n",
    "    alpha_clas.append(tmp/np.sum(mu))\n",
    "    beta_clas.append(tmp2/(N-np.sum(mu)))\n",
    "alpha_clas = np.array(alpha_clas)\n",
    "beta_clas = np.array(beta_clas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class model:\n",
    "    \"\"\"Classe qui encapsule l'apprentissage\"\"\"\n",
    "    \n",
    "    def __init__(self, maxIter = 10000, eta = 0.01):\n",
    "        \"\"\"Constructeur\"\"\"\n",
    "        self.maxIter = maxIter\n",
    "        self.eta = eta\n",
    "        \n",
    "    def initMu(self, y):\n",
    "        \"\"\"Initialisation de mu\"\"\"\n",
    "        mu = []\n",
    "        for i in range(0,N):\n",
    "            mu.append(np.sum(y[i])/R)\n",
    "        return mu\n",
    "    \n",
    "    def ai(self, alpha, y):\n",
    "        \"\"\"Update du vecteur a (1xN)\"\"\"\n",
    "        a = []\n",
    "        for i in range(0,N):\n",
    "            proda = 1\n",
    "        for j in range(0,R):\n",
    "            proda = proda*alpha[j]**(y[i][j])*(1-alpha[j])**(1-y[i][j])\n",
    "            a.append(proda)\n",
    "        self.a = a\n",
    "        \n",
    "    def bi(self, beta, y):\n",
    "        \"\"\"Update du vecteur b (1xN)\"\"\"\n",
    "        b = []\n",
    "        for i in range(0,N):\n",
    "            prodb = 1\n",
    "        for j in range(0,R):\n",
    "            prodb = prodb*beta[j]**(1-y[i][j])*(1-beta[j])**(y[i][j])\n",
    "            b.append(prodb)\n",
    "        self.b = b\n",
    "        \n",
    "    def pi(self, x, w):\n",
    "        \"\"\"Update du vecteur p (1xN)\"\"\"\n",
    "        p = []\n",
    "        for i in range(0,N):\n",
    "            p.append(sigma(x[i].dot(w.T)))\n",
    "        self.p = p\n",
    "        \n",
    "    def mui(self, a,b,p):\n",
    "        \"\"\"Update de\"\"\"\n",
    "        mu = []\n",
    "        for i in range(0,N):\n",
    "            mu.append(a[i]*p[i]/(a[i]*p[i]+b[i]*(1-p[i])))\n",
    "        self.mu = mu\n",
    "    \n",
    "    def EStep(x,y,alpha,beta,w):\n",
    "        CE = 0 #Conditionnal excepectation\n",
    "        a = ai(alpha,y)\n",
    "        b = bi(beta,y)\n",
    "        p = pi(x,w)\n",
    "        mu = mui(a,b,p)\n",
    "        for i in range(0,N):\n",
    "            CE += mu[i]*np.log(p[i])*a[i]+(1-mu[i])*np.log(1-p[i])*b[i]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
